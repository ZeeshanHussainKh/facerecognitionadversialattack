{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAwLb09GbLWv"
      },
      "source": [
        "Lets Begin Coding\n",
        "1. Download and Install required modules and libraries\n",
        "2. Import required data and connect with drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eijdBjhzUCc",
        "outputId": "bafe05d4-3744-4da1-f324-23a5362ef13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.7.3)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from lpips) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from lpips) (0.14.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.0->lpips) (4.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->lpips) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.2.1->lpips) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.2.1->lpips) (1.24.3)\n",
            "Installing collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bcolz\n",
            "  Downloading bcolz-1.2.1.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.8/dist-packages (from bcolz) (1.21.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Building wheel for bcolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bcolz: filename=bcolz-1.2.1-cp38-cp38-linux_x86_64.whl size=2883635 sha256=9e06f1f3ffba20a6c610d39e34e49b8a1a40fbef1abb2bec2889b50bbd35df10\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/f3/3b/5cf5f3997e4729700f17eb4faa8eb7dde1a209cdea66371b7a\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting focal-loss-torch\n",
            "  Downloading focal_loss_torch-0.1.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from focal-loss-torch) (1.13.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from focal-loss-torch) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->focal-loss-torch) (4.4.0)\n",
            "Installing collected packages: focal-loss-torch\n",
            "Successfully installed focal-loss-torch-0.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PTable\n",
            "  Downloading PTable-0.9.2.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: PTable\n",
            "  Building wheel for PTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PTable: filename=PTable-0.9.2-py3-none-any.whl size=22925 sha256=e71459e9e0bb9f6aa8a6e9fbc2e257c4b5e9d589e47928f0fa038a77af47bb09\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/02/8d8da2bca2223dda2f827949c88b2d82dc85dccbc2bb6265e5\n",
            "Successfully built PTable\n",
            "Installing collected packages: PTable\n",
            "Successfully installed PTable-0.9.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install lpips\n",
        "!pip install bcolz #bcolz 1.2.0\n",
        "!pip install torch torchvision\n",
        "#!pip install mxnet-cu90 #optional, for data processing MXNet 1.3.1\n",
        "!pip install focal-loss-torch\n",
        "!pip install split-folders # Used for split folders into train and val datasets or in our case split data into gallery and probe\n",
        "!pip install PTable\n",
        "#https://torchmetrics.readthedocs.io/en/latest/image/learned_perceptual_image_patch_similarity.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSc74we_zeWk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import lpips\n",
        "import torchvision.transforms as transforms\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# used to supress display of warnings\n",
        "import warnings\n",
        "from sklearn.metrics import precision_recall_curve,accuracy_score,f1_score,precision_score,recall_score\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import os\n",
        "\n",
        "#from tensorboardX import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "#4\n",
        "import cv2\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "#5\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#66\n",
        "from easydict import EasyDict as edict\n",
        "from pathlib import Path\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torchvision import transforms as trans\n",
        "from torch.utils.data import Dataset, ConcatDataset, DataLoader\n",
        "from torchvision import transforms as trans\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "import numpy as np\n",
        "import cv2\n",
        "import bcolz\n",
        "import pickle\n",
        "\n",
        "\n",
        "import splitfolders\n",
        "from torch import nn, optim, as_tensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.init import *\n",
        "from torchvision import transforms, utils, datasets, models\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from pdb import set_trace\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from skimage import io, transform\n",
        "from tqdm import trange, tqdm\n",
        "import csv\n",
        "import glob\n",
        "import dlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prettytable import PrettyTable\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7xI6wdy-8-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850875aa-21fe-4a88-ef45-4b322fb4c8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1l7xEBH9vu4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36dee80-c09d-4f9e-b476-1800fd0ae808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1zwzhRkZ80H2xZrn02Z1yt-rw_JDFgkmX/Lowkey code/supp_material\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Lowkey code/supp_material'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtwO8e677uh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a43e8d-372c-4af9-d2c9-37f110756bd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \u001b[0m\u001b[01;34malign\u001b[0m/               imgattacked2.png         pnet.npy\n",
            " attack1.png          imgattacked.png          requirements.txt\n",
            " attack_dir_warp.py   imgattackshalwar.JPG     rnet.npy\n",
            " \u001b[01;34mbackbone\u001b[0m/           'Lowkey test run.ipynb'   \u001b[01;34mutil\u001b[0m/\n",
            " \u001b[01;34mface\u001b[0m/                \u001b[01;34mmodels\u001b[0m/\n",
            " \u001b[01;34mflagged\u001b[0m/             onet.npy\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PbZtSX2-Q8I"
      },
      "outputs": [],
      "source": [
        "#convert to tensor\n",
        "to_tensor = transforms.ToTensor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw7DIssGcdbS"
      },
      "source": [
        "A little info about folders\n",
        "1. Align,util, models and backbone are imported from lowkey. Align is a copy of similar folder from FaceEvolve.\n",
        "2. Face is a clone of complete repository of FaceEvolve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JnQag1_Oo1q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QPSfXEK2kY_"
      },
      "outputs": [],
      "source": [
        "from util.prepare_utils import prepare_models,prepare_dir_vec,get_ensemble,extract_features # Used to load attack backbone in code\n",
        "from util.feature_extraction_utils import normalize_transforms,feature_extractor\n",
        "from util.attack_utils import Attack\n",
        "from align.detector import detect_faces\n",
        "from align.align_trans import get_reference_facial_points,warp_and_crop_face\n",
        "from backbone.model_irse import IR_152\n",
        "import lpips\n",
        "from face.applications.align.visualization_utils import show_results\n",
        "\n",
        "#1\n",
        "\n",
        "from face.head.metrics import ArcFace,CosFace,SphereFace\n",
        "from face.util.utils import make_weights_for_balanced_classes, get_val_data,separate_irse_bn_paras, separate_resnet_bn_paras, warm_up_lr, schedule_lr, perform_val, get_time, buffer_val, AverageMeter, accuracy\n",
        "\n",
        "#2\n",
        "\n",
        "from backbone.model_irse import IR_50, IR_101, IR_152, IR_SE_50, IR_SE_101, IR_SE_152\n",
        "from backbone.model_resnet import ResNet_50, ResNet_101, ResNet_152\n",
        "\n",
        "from face.loss.focal import FocalLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9oHw3urciGc"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS9x6iju4jsU",
        "outputId": "9471023e-843a-42fc-938f-fdb5c095e96e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bLLckiok18r"
      },
      "source": [
        " Parameters for lowkey adversial Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ho1wI39O-xci"
      },
      "outputs": [],
      "source": [
        "# Parameters for lowkey adversial Attack\n",
        "eps = 0.05\n",
        "n_iters = 50 # No of epooch for the attack\n",
        "input_size = [112, 112] # Input size model expects\n",
        "attack_type = 'lpips' # attack type used\n",
        "c_tv = None\n",
        "c_sim = 0.05\n",
        "lr = 0.0025 # the learning rate to optimize attack on\n",
        "net_type = 'alex'\n",
        "noise_size = 0.005 # noise size used\n",
        "n_starts = 1\n",
        "kernel_size_gf = 7 # gaussian smoothing window\n",
        "sigma_gf = 3 # sigma for gaussain smoothing\n",
        "combination = True # A switch to use gaussain smoothing together in attack or not\n",
        "using_subspace = False\n",
        "V_reduction_root = './'\n",
        "direction = 1\n",
        "crop_size = 112\n",
        "scale = crop_size / 112 #1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEA1GJDrdO2C"
      },
      "source": [
        "Parameters for training by Face Evolve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDSkFupCdKzA"
      },
      "outputs": [],
      "source": [
        "\n",
        "EMBEDDING_SIZE = 512 # feature dimension\n",
        "BATCH_SIZE = 512\n",
        "DROP_LAST = True # whether drop the last batch to ensure consistent batch_norm statistics\n",
        "LR = 0.1 # initial LR\n",
        "NUM_EPOCH = 120 # total epoch number (use the firt 1/25 epochs to warm up)\n",
        "WEIGHT_DECAY = 5e-4 # do not apply to batch_norm parameters\n",
        "MOMENTUM = 0.9\n",
        "STAGES = [35, 65, 95] # epoch stages to decay learning rate\n",
        "HEAD_NAME = 'ArcFace' # support:  ['Softmax', 'ArcFace', 'CosFace', 'SphereFace', 'Am_softmax']\n",
        "LOSS_NAME = 'Focal' # support: ['Focal', 'Softmax']\n",
        "\n",
        "#INPUT_SIZE = [112, 112] # support: [112, 112] and [224, 224]\n",
        "RGB_MEAN = [0.5, 0.5, 0.5] # for normalize inputs to [-1, 1]\n",
        "\n",
        "#DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "MULTI_GPU = True # flag to use multiple GPUs; if you choose to train with single GPU, you should first run \"export CUDA_VISILE_DEVICES=device_id\" to specify the GPU card you want to use\n",
        "GPU_ID = [0] # specify your GPU ids\n",
        "PIN_MEMORY = True\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "RGB_MEAN = [0.5, 0.5, 0.5] # for normalize inputs to [-1, 1]\n",
        "RGB_STD = [0.5, 0.5, 0.5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load all the **Models**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "onvbmXgKph-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oBcaXD_6zNS"
      },
      "outputs": [],
      "source": [
        "model_backbones = ['IR_152', 'IR_152', 'ResNet_152', 'ResNet_152'] # Model backbone for ensemble\n",
        "model_roots = ['models/Backbone_IR_152_Arcface_Epoch_112.pth', 'models/Backbone_IR_152_Cosface_Epoch_70.pth', \\\n",
        "'models/Backbone_ResNet_152_Arcface_Epoch_65.pth', 'models/Backbone_ResNet_152_Cosface_Epoch_68.pth'] # Roots of the models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P5p85NZo7Ij",
        "outputId": "264ad949-ace9-4685-d01f-143859a7c4ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Load an IR_152 Cosface model\n",
        "PATH = 'models/Backbone_IR_152_Cosface_Epoch_70.pth'\n",
        "IR_152C = IR_152(input_size=input_size)\n",
        "IR_152C.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Load IR_152 Arc Face model\n",
        "PATH1 = 'models/Backbone_IR_152_Arcface_Epoch_112.pth'\n",
        "IR_152A = IR_152(input_size=input_size)\n",
        "IR_152A.load_state_dict(torch.load(PATH1))\n",
        "\n",
        "#Load ResNet 152 Arc Face Model\n",
        "PATH2 = 'models/Backbone_ResNet_152_Arcface_Epoch_65.pth'\n",
        "RESNET_152A = ResNet_152(input_size=input_size)\n",
        "RESNET_152A.load_state_dict(torch.load(PATH2))\n",
        "\n",
        "\n",
        "# Load Resnet 152 CosFace Model\n",
        "PATH3 = 'models/Backbone_ResNet_152_Cosface_Epoch_68.pth'\n",
        "RESNET_152C = ResNet_152(input_size=input_size)\n",
        "RESNET_152C.load_state_dict(torch.load(PATH3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy4ISChOAihv",
        "outputId": "c5e24d04-9537-45b1-c515-113dcffdb7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Attack Backbone Checkpoint '['models/Backbone_IR_152_Arcface_Epoch_112.pth', 'models/Backbone_IR_152_Cosface_Epoch_70.pth', 'models/Backbone_ResNet_152_Arcface_Epoch_65.pth', 'models/Backbone_ResNet_152_Cosface_Epoch_68.pth']'\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "# Generate lowkey ensemble attack model\n",
        "models_attack, V_reduction, dim = prepare_models(model_backbones,\n",
        "              input_size,\n",
        "              model_roots,\n",
        "              kernel_size_gf,\n",
        "              sigma_gf,\n",
        "              combination,\n",
        "              using_subspace,\n",
        "              V_reduction_root)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Now lets perform evaluation on clean data gallery - 24 identities\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ANJowiV5pqVo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnRCRE8HpwHX"
      },
      "outputs": [],
      "source": [
        "# define data transform\n",
        "transform = transforms.Compose([\n",
        "      transforms.Resize([int(128 * input_size[0] / 112), int(128 * input_size[0] / 112)]),  # smaller side resized\n",
        "      transforms.CenterCrop([input_size[0], input_size[1]]),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean = RGB_MEAN, std = RGB_STD)])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpeRRQ9PocVR"
      },
      "outputs": [],
      "source": [
        "#Define Loaders for all different galleries and corresponding probe\n",
        "\n",
        "# Define the Loader for Clean data gallery and probe and the adversial infected gallery.\n",
        "\n",
        "gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/gallery' #90% of validation data\n",
        "probe_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/probe' # 10% of validation data\n",
        "adversial_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble' #90% of validation data\n",
        "#Load Datasetsfor clean gallery and adversial infected gallery\n",
        "\n",
        "gallery_dataset = datasets.ImageFolder(gallery_root, transform)\n",
        "probe_dataset = datasets.ImageFolder(probe_root, transform)\n",
        "adversial_gallery_dataset = datasets.ImageFolder(adversial_gallery_root, transform)\n",
        "# Define Data Loaders\n",
        "gallery_loader = torch.utils.data.DataLoader(gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n",
        "probe_loader = torch.utils.data.DataLoader(probe_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n",
        "adversial_loader = torch.utils.data.DataLoader(adversial_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUXzHX044K7Q",
        "outputId": "80945f68-0e80-4edf-88f4-7444434d0bbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1240\n"
          ]
        }
      ],
      "source": [
        "print(len(gallery_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(adversial_gallery_dataset))"
      ],
      "metadata": {
        "id": "7Qlygs5C7VhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c5f59f-8360-49c1-8f7a-88c5dba577ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZhqxj5K4OF4",
        "outputId": "868edca8-e46c-477e-ec6c-36686201aa42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        }
      ],
      "source": [
        "print(len(probe_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "105d_jKoshWz",
        "outputId": "b42c78dc-a9b2-45d7-c071-526e7c95282d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 1240\n",
              "    Root location: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/gallery\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=[128, 128], interpolation=bilinear, max_size=None, antialias=None)\n",
              "               CenterCrop(size=[112, 112])\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "gallery_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_WS38HRsjeQ",
        "outputId": "8c82a5de-57c1-4165-d472-5b93088b4bd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 151\n",
              "    Root location: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/probe\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=[128, 128], interpolation=bilinear, max_size=None, antialias=None)\n",
              "               CenterCrop(size=[112, 112])\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "probe_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKPdyDzrqm7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59df2950-9899-4cac-c1be-7dfd3fcee14a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 1240\n",
              "    Root location: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=[128, 128], interpolation=bilinear, max_size=None, antialias=None)\n",
              "               CenterCrop(size=[112, 112])\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "adversial_gallery_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQE4nImsr3Q5"
      },
      "outputs": [],
      "source": [
        "# Methods to Process features of the data for face recognition\n",
        "def l2_norm(input, axis = 1):\n",
        "    norm = torch.norm(input, 2, axis, True)\n",
        "    output = torch.div(input, norm)\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def de_preprocess(tensor):\n",
        "\n",
        "    return tensor * 0.5 + 0.5\n",
        "\n",
        "\n",
        "hflip = transforms.Compose([\n",
        "            de_preprocess,\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.functional.hflip,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "        ])\n",
        "\n",
        "\n",
        "def hflip_batch(imgs_tensor):\n",
        "    hfliped_imgs = torch.empty_like(imgs_tensor)\n",
        "    for i, img_ten in enumerate(imgs_tensor):\n",
        "        hfliped_imgs[i] = hflip(img_ten)\n",
        "\n",
        "    return hfliped_imgs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nf55jHnguBku"
      },
      "outputs": [],
      "source": [
        "# Define a function for feature extractor\n",
        "\n",
        "def extract_feature_face(loader, model, embedding_size = 512, batch_size = 16, device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), tta = True):\n",
        "\n",
        "    NUM_CLASS = len(loader.dataset.classes)\n",
        "    print(\"Number of Classes: {}\".format(NUM_CLASS))\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # extract features\n",
        "    model.eval() # set to evaluation mode\n",
        "    idx = 0\n",
        "    features = np.zeros([len(loader.dataset), embedding_size])\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Features zeros shape: {}\".format(features.shape))\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        iter_loader = iter(loader)\n",
        "        while idx + batch_size <= len(loader.dataset):\n",
        "            print(\"=\" * 60)\n",
        "            print(\"idx + batch_size <= len(loader.dataset)\")\n",
        "            batch, _ = next(iter_loader)\n",
        "            features[idx:idx + batch_size] = l2_norm(model(batch.to(device))).cpu()\n",
        "            print(\"=\" * 60)\n",
        "            print(\"Features l2_norm shape else : {}\".format(features.shape))\n",
        "            idx += batch_size\n",
        "            print(\"The value of idx is : {}\".format(idx))\n",
        "\n",
        "        if idx < len(loader.dataset):\n",
        "            batch, _ = next(iter_loader)\n",
        "            print(\"=\" * 60)\n",
        "            print(\"idx<len now\")\n",
        "            features[idx:] = l2_norm(model(batch.to(device)).cpu())\n",
        "            print(\"=\" * 60)\n",
        "            print(\"Features l2_norm else shape : {}\".format(features.shape))\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "    for img_path, _ in loader.dataset.samples:\n",
        "        img = cv2.imread(img_path)\n",
        "        images.append(img_path)\n",
        "        label = _\n",
        "        label = labels.append(label)\n",
        "    return labels,images, features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Load gallery,probe and labels for IR-152 ArcFace model\n",
        "\n",
        "gallery_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_IR_152A_features.npy\")\n",
        "gallery_labels_IR_152A =np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_labels_IR_152A.npy\")\n",
        "probe_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_IR_152A_features.npy\")\n",
        "probe_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_labels_IR_152A.npy\")\n",
        "\n",
        "# #Load gallery,probe and labels for IR-152 CosFace model\n",
        "\n",
        "gallery_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_features_IR_152C.npy\")\n",
        "gallery_labels_IR_152C =np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_labels_IR_152C.npy\")\n",
        "probe_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_features_IR_152C.npy\")\n",
        "probe_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_labels_IR_152C.npy\")\n",
        "\n",
        "# #Load gallery,probe and labels for RESNET-152 ArcFace model\n",
        "\n",
        "gallery_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_features_RESNET_152A.npy\")\n",
        "gallery_labels_RESNET_152A =np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_labels_RESNET_152A.npy\")\n",
        "probe_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_features_RESNET_152A.npy\")\n",
        "probe_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_labels_RESNET_152A.npy\")\n",
        "\n",
        "# #Load gallery,probe and labels for RESNET-152 CosFace model\n",
        "\n",
        "gallery_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_features_RESNET_152C.npy\")\n",
        "gallery_labels_RESNET_152C =np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_labels_RESNET_152C.npy\")\n",
        "probe_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_features_RESNET_152C.npy\")\n",
        "probe_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_labels_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "31N8rUOU_klF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JujJprPX7SiZ"
      },
      "outputs": [],
      "source": [
        "from numpy import dot, sqrt\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    return dot(x, y) / (sqrt(dot(x, x)) * sqrt(dot(y, y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Lets define a function that uses gallery and probe features to compute top1 and top 5 accuracy\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NqgObOh6qMVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFFDwPCEkNr7",
        "outputId": "093cc7d4-4b83-4b02-d06a-50cecebd0161"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 4, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import heapq\n",
        "heapq.nlargest(3,[1,2,3,4,5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUbOfYQYkPb3",
        "outputId": "23c2614e-4806-4177-9fba-2b037a4b762a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "gallery_labels_IR_152A[100:120]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIzzt4MGkQ_y",
        "outputId": "6131a996-e641-4a5f-cae8-6db5d1810780"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "probe_labels_IR_152A[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orYe7UKHkXpL",
        "outputId": "06c87bda-3c05-4ea5-aa1b-b4710930432f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "from numpy import dot, sqrt\n",
        "\n",
        "def get_best_match(source,target,real_label,all_labels,n=1):\n",
        "  \"takes source feature and target features, along with source label and target labels. Returns TRUE if the label of source exists in top N labels of targets\"\n",
        "  sims=[]\n",
        "  for val in target:\n",
        "    cos = cosine_similarity(source,val)\n",
        "    sims.append(cos) # calculate cosine similarity with all\n",
        "\n",
        "  vals=heapq.nlargest(n,sims) # n largest similarity values\n",
        "  indices=[]\n",
        "  possible_labels=[]\n",
        "  for val in vals:\n",
        "    ind=sims.index(val) # index of largest similarity\n",
        "    indices.append(ind)\n",
        "    possible_labels.append(all_labels[ind]) # get label corresponding to best matches\n",
        "  if real_label in possible_labels: # the given value exists in the top N similarities\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "get_best_match(probe_features_IR_152A[11],gallery_features_IR_152A,probe_labels_IR_152A[11],gallery_labels_IR_152A,n=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XokDQUTzzE3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqRNZY8YkYu3",
        "outputId": "747f0069-fa0b-4d7d-f0c1-209dc34ded48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "get_best_match(probe_features_IR_152A[100],gallery_features_IR_152A[:99],probe_labels_IR_152A[100],gallery_labels_IR_152A[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0cJxiElEwgN"
      },
      "outputs": [],
      "source": [
        "# Compute top 1 and top 5 accuracy of model and generate the evaluation table as lowkey here\n",
        "def get_accuracy(probe_features,probe_labels,gallery_features,gallery_labels,k=1):\n",
        "  correct=0\n",
        "  with tqdm(total=len(probe_features)) as pbar:\n",
        "    for i,val in enumerate(probe_features):\n",
        "      flag=get_best_match(val,gallery_features,probe_labels[i],gallery_labels,n=k)\n",
        "      if flag:\n",
        "        correct+=1\n",
        "      pbar.update(1)\n",
        "  accuracy = correct/len(probe_features)\n",
        "\n",
        "  return  accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56a4y-W9m4jh",
        "outputId": "75af840d-4f49-4f6b-9df6-cc9e0671fdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 151/151 [00:01<00:00, 96.59it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 95.34it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 92.94it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 94.32it/s]\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy for IR_152A\n",
        "clean_top1_accuracy_IR152A = get_accuracy(probe_features=probe_features_IR_152A,probe_labels=probe_labels_IR_152A,\n",
        "                                          gallery_features=gallery_features_IR_152A,gallery_labels=gallery_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "clean_top1_accuracy_IR152C = get_accuracy(probe_features=probe_features_IR_152C,probe_labels=probe_labels_IR_152C,\n",
        "                                          gallery_features=gallery_features_IR_152C,gallery_labels=gallery_labels_IR_152C,k=1)\n",
        "\n",
        "clean_top1_accuracy_RESNET152A = get_accuracy(probe_features=probe_features_RESNET_152A,probe_labels=probe_labels_RESNET_152A,\n",
        "                                          gallery_features=gallery_features_RESNET_152A,gallery_labels=gallery_labels_RESNET_152A,k=1)\n",
        "\n",
        "clean_top1_accuracy_RESNET152C = get_accuracy(probe_features=probe_features_RESNET_152C,probe_labels=probe_labels_RESNET_152C,\n",
        "                                          gallery_features=gallery_features_RESNET_152C,gallery_labels=gallery_labels_RESNET_152C,k=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SEDJT5Z4cxT",
        "outputId": "de3ee63e-5cf8-4d68-facf-9fd93559c9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 151/151 [00:02<00:00, 62.11it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 94.43it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 96.16it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 94.93it/s]\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy for IR_152A\n",
        "clean_top5_accuracy_IR152A = get_accuracy(probe_features=probe_features_IR_152A,probe_labels=probe_labels_IR_152A,\n",
        "                                          gallery_features=gallery_features_IR_152A,gallery_labels=gallery_labels_IR_152A,k=5)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "clean_top5_accuracy_IR152C = get_accuracy(probe_features=probe_features_IR_152C,probe_labels=probe_labels_IR_152C,\n",
        "                                          gallery_features=gallery_features_IR_152C,gallery_labels=gallery_labels_IR_152C,k=5)\n",
        "\n",
        "clean_top5_accuracy_RESNET152A = get_accuracy(probe_features=probe_features_RESNET_152A,probe_labels=probe_labels_RESNET_152A,\n",
        "                                          gallery_features=gallery_features_RESNET_152A,gallery_labels=gallery_labels_RESNET_152A,k=5)\n",
        "\n",
        "clean_top5_accuracy_RESNET152C = get_accuracy(probe_features=probe_features_RESNET_152C,probe_labels=probe_labels_RESNET_152C,\n",
        "                                          gallery_features=gallery_features_RESNET_152C,gallery_labels=gallery_labels_RESNET_152C,k=5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIFnmp5zoiuw",
        "outputId": "b38b2224-a051-4789-80f6-5812c7be67a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on clean images for IR_152A is: 0.9933774834437086\n",
            "The top1 Accuracy on clean images for IR_152C is: 0.9933774834437086\n",
            "The top1 Accuracy on clean images for RESNET_152A is: 0.9933774834437086\n",
            "The top1 Accuracy on clean images for RESNET_152C is: 0.9933774834437086\n"
          ]
        }
      ],
      "source": [
        "print(\"The top1 Accuracy on clean images for IR_152A is: {}\".format(clean_top1_accuracy_IR152A))\n",
        "print(\"The top1 Accuracy on clean images for IR_152C is: {}\".format(clean_top1_accuracy_IR152C))\n",
        "print(\"The top1 Accuracy on clean images for RESNET_152A is: {}\".format(clean_top1_accuracy_RESNET152A))\n",
        "print(\"The top1 Accuracy on clean images for RESNET_152C is: {}\".format(clean_top1_accuracy_RESNET152C))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R4qZ_Ys4piM",
        "outputId": "b63f226b-24a9-4554-a0a1-046ab260c88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on clean images for IR_152A is: 0.9933774834437086\n",
            "The top5 Accuracy on clean images for IR_152C is: 0.9933774834437086\n",
            "The top5 Accuracy on clean images for RESNET_152A is: 0.9933774834437086\n",
            "The top5 Accuracy on clean images for RESNET_152C is: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"The top5 Accuracy on clean images for IR_152A is: {}\".format(clean_top5_accuracy_IR152A))\n",
        "print(\"The top5 Accuracy on clean images for IR_152C is: {}\".format(clean_top5_accuracy_IR152C))\n",
        "print(\"The top5 Accuracy on clean images for RESNET_152A is: {}\".format(clean_top5_accuracy_RESNET152A))\n",
        "print(\"The top5 Accuracy on clean images for RESNET_152C is: {}\".format(clean_top5_accuracy_RESNET152C))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Now Lets perform the attack on 5 identities and insert them back to gallery to create adversial gallery\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FPS7Gek2AwHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smWa8sWAIV0L"
      },
      "outputs": [],
      "source": [
        "# Function to protect a single image\n",
        "\n",
        "def protect_image(image):\n",
        "  #img = Image.fromarray(img)\n",
        "  img = Image.open(image)\n",
        "  #print(img)\n",
        "  reference = get_reference_facial_points(default_square=True) * scale\n",
        "  print(\"The value for reference in get reference facial points  is {}\".format(reference))\n",
        "  h,w,c = np.array(img).shape\n",
        "  print (h,w,c)\n",
        "\n",
        "  b_box,landmarks = detect_faces(img)\n",
        "  #show_results(img, _, landmarks)\n",
        "  print(\"The size of landmarks is {}\".format(landmarks.size))\n",
        "  #print(\"The value for _ in detect faces is {}\".format(_))\n",
        "  # (landmarks)\n",
        "  facial5points = [[landmarks[0][j], landmarks[0][j + 5]] for j in range(5)]\n",
        "  #print(\"The value for _ in detect faces is {} end \".format(facial5points))\n",
        "  b_box, tfm = warp_and_crop_face(np.array(img), facial5points, reference, crop_size=(crop_size, crop_size))\n",
        "  print(\"The value for tfm in warp_and_crop_face is {}  \".format(tfm))\n",
        "  # pytorch transform\n",
        "  theta = normalize_transforms(tfm, w, h)\n",
        "  tensor_img = to_tensor(img).unsqueeze(0).to(device)\n",
        "  print(\"The value for theta in normalize_transforms(tfm, w, h) is {}  \".format(theta))\n",
        "  V_reduction = None\n",
        "  dim = 512\n",
        "\n",
        "  # Find gradient direction vector\n",
        "  dir_vec_extractor = get_ensemble(models = models_attack, sigma_gf=None, kernel_size_gf=None, combination=False, V_reduction=V_reduction, warp=True, theta_warp=theta)\n",
        "  dir_vec = prepare_dir_vec(dir_vec_extractor, tensor_img, dim, combination)\n",
        "  print(\"The value for direction vector of gradient in image is {}  \".format(dir_vec))\n",
        "  img_attacked = tensor_img.clone()\n",
        "  attack = Attack(models_attack, dim, attack_type,\n",
        "                  eps, c_sim, net_type, lr, n_iters,\n",
        "                  noise_size, n_starts, c_tv, sigma_gf,\n",
        "                  kernel_size_gf, combination, warp=True,\n",
        "                  theta_warp=theta, V_reduction=V_reduction)\n",
        "  img_attacked = attack.execute(tensor_img, dir_vec, direction).detach().cpu()\n",
        "\n",
        "  img_attacked_pil = transforms.ToPILImage()(img_attacked[0])\n",
        "  return img_attacked_pil,dir_vec_extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVEecnxCIb2M"
      },
      "outputs": [],
      "source": [
        "#Now lets create a  function to attack a directory of images  with lowkey attack\n",
        "\n",
        "def protect_dir(dirs_root,model,save_dir):\n",
        "\n",
        "  for img_name in tqdm(os.listdir(dirs_root)):\n",
        "\n",
        "\n",
        "    img_root = os.path.join(dirs_root, img_name)\n",
        "    #new_img_root = os.path.join(save_dir, img_name)\n",
        "    print(\"The image processed is : {}\".format(img_root))\n",
        "    print('Finding reference points')\n",
        "    reference = get_reference_facial_points(default_square=True) * scale\n",
        "    img = Image.open(img_root)\n",
        "    #h,w,c = np.array(img).shape\n",
        "    h,w,c = np.array(img).shape\n",
        "    #print(\"The value for reference in get reference facial points  is {}\".format(reference))\n",
        "    #print (h,w,c)\n",
        "    ## Detects facial points ##\n",
        "    b_box,landmarks = detect_faces(img)\n",
        "    facial5points = [[landmarks[0][j], landmarks[0][j + 5]] for j in range(5)]\n",
        "    #print(\"The value for _ in detect faces is {} end \".format(facial5points))\n",
        "    b_box, tfm = warp_and_crop_face(np.array(img), facial5points, reference, crop_size=(crop_size, crop_size))\n",
        "    #print(\"The value for tfm in warp_and_crop_face is {}  \".format(tfm))\n",
        "\n",
        "    ## find pytorch transform\n",
        "    theta = normalize_transforms(tfm, w, h)\n",
        "    tensor_img = to_tensor(img).unsqueeze(0).to(device)\n",
        "    #print(\"The value for theta in normalize_transforms(tfm, w, h) is {}  \".format(theta))\n",
        "\n",
        "    V_reduction = None\n",
        "    dim = 512\n",
        "\n",
        "  # Find gradient direction vector i.e find the feature vector extractor\n",
        "    dir_vec_extractor = get_ensemble(models=model, sigma_gf=None, kernel_size_gf=None, combination=False, V_reduction=V_reduction, warp=True, theta_warp=theta)\n",
        "    dir_vec = prepare_dir_vec(dir_vec_extractor, tensor_img, dim, combination).to(device)\n",
        "  #print(\"The value for direction vector of gradient in image is {}  \".format(dir_vec))\n",
        "\n",
        "  # Perform Low key attack\n",
        "    img_attacked = tensor_img.clone()\n",
        "    attack = Attack(model, dim, attack_type,\n",
        "                  eps, c_sim, net_type, lr, n_iters,\n",
        "                  noise_size, n_starts, c_tv, sigma_gf,\n",
        "                  kernel_size_gf, combination, warp=True,\n",
        "                  theta_warp=theta, V_reduction=V_reduction).to(device)\n",
        "    img_attacked = attack.execute(tensor_img, dir_vec, direction).detach().cpu()\n",
        "    print(\"attack Executed\")\n",
        "    img_attacked_pil = transforms.ToPILImage()(img_attacked[0])\n",
        "    img_attacked_pil.save(img_root[:-4] + 'protected.png')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXO1NDt4G7cJ"
      },
      "outputs": [],
      "source": [
        "# Now onto adversial attack on some identities\n",
        "lowkey_id_1 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Adam_Brody\"\n",
        "lowkey_id_2 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/AndyGarcia\"\n",
        "lowkey_id_3 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis\"\n",
        "lowkey_id_4 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck\"\n",
        "lowkey_id_5 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiK5jGvztOdV",
        "outputId": "36affe0a-8409-4486-9bce-7d3ba79a8296"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/58 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5918_3439.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/58 [00:36<34:26, 36.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5896_3424.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/58 [01:13<34:32, 37.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5956_3451.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 3/58 [01:51<34:04, 37.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5908_3432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 4/58 [02:27<33:06, 36.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5875_3412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 5/58 [03:03<32:24, 36.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5914_3436.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 6/58 [03:39<31:27, 36.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5904_3430.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 7/58 [04:16<30:58, 36.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5911_3435.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 8/58 [04:52<30:16, 36.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5871_3411.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 9/58 [05:29<29:47, 36.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5974_3459.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 10/58 [06:06<29:28, 36.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5793_3359.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 11/58 [06:43<28:48, 36.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5935_3444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 12/58 [07:21<28:26, 37.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5880_3415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 13/58 [07:58<27:52, 37.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5903_3429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 14/58 [08:35<27:15, 37.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5844_3393.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 15/58 [09:12<26:39, 37.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5700_3317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 16/58 [09:50<26:11, 37.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5726_3329.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 17/58 [10:28<25:35, 37.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5936_3445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 18/58 [11:06<25:00, 37.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5751_3340.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 19/58 [11:43<24:23, 37.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5740_3336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 20/58 [12:22<24:01, 37.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5762_3345.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 21/58 [12:59<23:14, 37.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5869_3410.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 22/58 [13:36<22:32, 37.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5737_3334.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 23/58 [14:14<21:54, 37.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5725_3328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████▏     | 24/58 [14:51<21:15, 37.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5782_3354.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 25/58 [15:28<20:32, 37.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5738_3335.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 26/58 [16:06<19:58, 37.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5689_3311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 27/58 [16:44<19:23, 37.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5790_3356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 28/58 [17:20<18:35, 37.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5664_3295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 29/58 [17:57<17:55, 37.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5701_3318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 30/58 [18:35<17:24, 37.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5720_3327.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 31/58 [19:13<16:51, 37.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5772_3349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 32/58 [19:49<16:06, 37.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5707_3321.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 33/58 [20:27<15:33, 37.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5792_3358.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▊    | 34/58 [21:05<14:59, 37.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5813_3374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 35/58 [21:41<14:16, 37.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5688_3310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 36/58 [22:19<13:39, 37.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5697_3315.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 37/58 [22:57<13:09, 37.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5657_3291.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 38/58 [23:34<12:27, 37.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5640_3278.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 39/58 [24:11<11:46, 37.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5656_3290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 40/58 [24:48<11:11, 37.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5635_3274.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 41/58 [25:25<10:31, 37.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5651_3286.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 42/58 [26:02<09:51, 36.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5639_3277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 43/58 [26:38<09:13, 36.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5666_3296.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 44/58 [27:17<08:44, 37.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5685_3308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 45/58 [27:54<08:04, 37.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5634_3273.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 46/58 [28:30<07:24, 37.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5677_3304.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 47/58 [29:08<06:50, 37.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5648_3283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 48/58 [29:46<06:13, 37.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5641_3279.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 49/58 [30:23<05:34, 37.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5652_3287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 50/58 [31:00<04:58, 37.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5918_3439.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 51/58 [31:37<04:19, 37.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5896_3424.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 52/58 [32:13<03:41, 36.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5956_3451.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 53/58 [32:49<03:02, 36.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5908_3432.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 54/58 [33:26<02:27, 36.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5875_3412.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▍| 55/58 [34:02<01:49, 36.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5914_3436.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 56/58 [34:38<01:12, 36.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5904_3430.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 57/58 [35:15<00:36, 36.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Andy_Serkis/Andy_Serkis_5911_3435.protected.png\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 58/58 [35:51<00:00, 37.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=lowkey_id_3,model=models_attack)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "abded15c77b64851b2433c29a9c85ac6",
            "b865646675444ff5bd920db1101524ed",
            "c45a4d624c6944b083a1d99a9812a953",
            "aa18884468404ab2930318ab12f60f89",
            "031acb9ee2af4878a1508ee1cd1ff946",
            "dfe08893fafe47a68f9ef1232e393a06",
            "92682188a8c143698fe99486dc52bd00",
            "4cb15a84bdba4d0fb417c9f8772ccfa6",
            "739cc4ed8e2a4147af64d845da8b191d",
            "ec9f5b75d95441efbc1c4ef919e05feb",
            "891af9ef28404005810b6374e80ea819"
          ]
        },
        "id": "0DIlBzCCtPYc",
        "outputId": "34213036-c35a-4264-802b-feee0078f2ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/27 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8549_4727.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abded15c77b64851b2433c29a9c85ac6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 1/27 [00:51<22:28, 51.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8779_4882.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 2/27 [01:29<18:04, 43.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8681_4815.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 3/27 [02:07<16:27, 41.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8572_4742.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 15%|█▍        | 4/27 [02:43<15:00, 39.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8518_4699.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 5/27 [03:20<13:58, 38.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8479_4675.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 6/27 [03:56<13:05, 37.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8539_4718.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 7/27 [04:32<12:20, 37.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8486_4681.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 8/27 [05:11<11:55, 37.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8586_4750.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 9/27 [05:47<11:08, 37.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8525_4705.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 10/27 [06:23<10:25, 36.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8617_4771.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 11/27 [06:59<09:44, 36.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8480_4676.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 12/27 [07:37<09:15, 37.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8557_4733.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 13/27 [08:13<08:34, 36.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8519_4700.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 14/27 [08:49<07:55, 36.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8496_4684.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 15/27 [09:25<07:16, 36.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8526_4706.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 16/27 [10:03<06:46, 36.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8462_4663.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 17/27 [10:39<06:05, 36.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8607_4765.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 18/27 [11:15<05:27, 36.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8456_4657.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 19/27 [11:51<04:49, 36.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8603_4762.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 20/27 [12:26<04:11, 35.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8556_4732.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 21/27 [13:03<03:38, 36.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8477_4673.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 22/27 [13:39<03:00, 36.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8563_4737.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 23/27 [14:14<02:23, 35.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8471_4670.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 24/27 [14:50<01:47, 35.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8455_4656.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 25/27 [15:27<01:12, 36.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8461_4662.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▋| 26/27 [16:03<00:36, 36.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Ben_Affleck/Ben_Affleck_8476_4672.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 27/27 [16:38<00:00, 37.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=lowkey_id_4,model=models_attack)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd9VW0uctQX7",
        "outputId": "4bf3daf3-8c8e-4c1e-ceaf-6595e9763893"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/17 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_4109_2483.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 1/17 [00:35<09:27, 35.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3944_2366.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 2/17 [01:12<09:08, 36.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3938_2360.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 3/17 [01:48<08:25, 36.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_4002_2412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▎       | 4/17 [02:23<07:46, 35.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3977_2392.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 5/17 [02:59<07:08, 35.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3939_2361.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 6/17 [03:34<06:31, 35.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_4009_2417.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 7/17 [04:12<06:01, 36.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_4096_2477.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 8/17 [04:47<05:23, 35.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3942_2364.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 9/17 [05:22<04:45, 35.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3975_2390.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 10/17 [05:58<04:09, 35.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3943_2365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▍   | 11/17 [06:36<03:37, 36.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3971_2387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 12/17 [07:12<03:01, 36.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3947_2369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▋  | 13/17 [07:48<02:24, 36.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3957_2376.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 14/17 [08:24<01:48, 36.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3940_2362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 15/17 [09:01<01:13, 36.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3994_2404.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 16/17 [09:38<00:36, 36.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Alfred_Molina/Alfred_Molina_3952_2372.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 17/17 [10:14<00:00, 36.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=lowkey_id_5,model=models_attack)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmslo6F9cdw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6c8921-b86f-43f9-fb65-20d698a49cbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n"
          ]
        }
      ],
      "source": [
        "# # from matplotlib.patches import Arc\n",
        "# # Extract adversial gallery features for IR_152A\n",
        "# adversial_labels_IR_152A,adversial_images_IR_152A,adversial_features_IR_152A = extract_feature_face(loader=adversial_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_IR_152A.npy\", adversial_features_IR_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_IR_152A.npy\", adversial_labels_IR_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_images_IR_152A.npy\", adversial_images_IR_152A)\n",
        "\n",
        "# #Extract adversial gallery features for IR_152C\n",
        "# adversial_labels_IR_152C,adversial_images_IR_152C,adversial_features_IR_152C = extract_feature_face(loader=adversial_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_IR_152C.npy\", adversial_features_IR_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_IR_152C.npy\", adversial_labels_IR_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_images_IR_152C.npy\", adversial_images_IR_152C)\n",
        "\n",
        "\n",
        "# #Extract adversial gallery features for  RESNET_152A\n",
        "# adversial_labels_RESNET_152A,adversial_images_RESNET_152A,adversial_features_RESNET_152A = extract_feature_face(loader=adversial_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_RESNET_152A.npy\", adversial_features_RESNET_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_RESNET_152A.npy\", adversial_labels_RESNET_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_images_RESNET_152A.npy\", adversial_images_RESNET_152A)\n",
        "\n",
        "# #Extract adversial gallery features for RESNET_152C\n",
        "# adversial_labels_RESNET_152C,adversial_images_RESNET_152C,adversial_features_RESNET_152C = extract_feature_face(loader=adversial_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_RESNET_152C.npy\", adversial_features_RESNET_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_RESNET_152C.npy\", adversial_labels_RESNET_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_images_RESNET_152C.npy\", adversial_images_RESNET_152C)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGjonCptfWyt"
      },
      "outputs": [],
      "source": [
        "adversial_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_IR_152A.npy\")\n",
        "adversial_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_IR_152A.npy\")\n",
        "\n",
        "adversial_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_IR_152C.npy\")\n",
        "adversial_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_IR_152C.npy\")\n",
        "\n",
        "adversial_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_RESNET_152A.npy\")\n",
        "adversial_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_RESNET_152A.npy\")\n",
        "\n",
        "adversial_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_features_RESNET_152C.npy\")\n",
        "adversial_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_labels_RESNET_152C.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(gallery_features_IR_152A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Ix6nwkvMeG",
        "outputId": "1bb560b2-235c-4c3b-f61b-7a37f8a1c28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(probe_features_IR_152A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VarzerNXvKHg",
        "outputId": "8add035e-9ae1-471e-b947-8fb3fb2fa31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(adversial_features_IR_152A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7as61oLvIAB",
        "outputId": "df226b76-613f-4562-ef34-257981d23d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPmPROKzpoOQ",
        "outputId": "ed728059-4aa3-45f2-d7a2-069e76963847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 151/151 [00:02<00:00, 69.01it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 91.80it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 94.13it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 92.87it/s]\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy for IR_152A\n",
        "adversial_top1_accuracy_IR152A = get_accuracy(probe_features=probe_features_IR_152A,probe_labels=probe_labels_IR_152A,\n",
        "                                          gallery_features=adversial_features_IR_152A,gallery_labels=adversial_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "adversial_top1_accuracy_IR152C = get_accuracy(probe_features=probe_features_IR_152C,probe_labels=probe_labels_IR_152C,\n",
        "                                          gallery_features=adversial_features_IR_152C,gallery_labels=adversial_labels_IR_152C,k=1)\n",
        "\n",
        "adversial_top1_accuracy_RESNET152A = get_accuracy(probe_features=probe_features_RESNET_152A,probe_labels=probe_labels_RESNET_152A,\n",
        "                                          gallery_features=adversial_features_RESNET_152A,gallery_labels=adversial_labels_RESNET_152A,k=1)\n",
        "\n",
        "adversial_top1_accuracy_RESNET152C = get_accuracy(probe_features=probe_features_RESNET_152C,probe_labels=probe_labels_RESNET_152C,\n",
        "                                          gallery_features=adversial_features_RESNET_152C,gallery_labels=adversial_labels_RESNET_152C,k=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL78xXBU5ZJy",
        "outputId": "19f086bc-ca9e-40c1-8bce-69acc0c64fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 151/151 [00:01<00:00, 88.21it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 92.58it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 93.53it/s]\n",
            "100%|██████████| 151/151 [00:01<00:00, 89.78it/s]\n"
          ]
        }
      ],
      "source": [
        "# calculate accuracy for IR_152A\n",
        "adversial_top5_accuracy_IR152A = get_accuracy(probe_features=probe_features_IR_152A,probe_labels=probe_labels_IR_152A,\n",
        "                                          gallery_features=adversial_features_IR_152A,gallery_labels=adversial_labels_IR_152A,k=5)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "adversial_top5_accuracy_IR152C = get_accuracy(probe_features=probe_features_IR_152C,probe_labels=probe_labels_IR_152C,\n",
        "                                          gallery_features=adversial_features_IR_152C,gallery_labels=adversial_labels_IR_152C,k=5)\n",
        "\n",
        "adversial_top5_accuracy_RESNET152A = get_accuracy(probe_features=probe_features_RESNET_152A,probe_labels=probe_labels_RESNET_152A,\n",
        "                                          gallery_features=adversial_features_RESNET_152A,gallery_labels=adversial_labels_RESNET_152A,k=5)\n",
        "\n",
        "adversial_top5_accuracy_RESNET152C = get_accuracy(probe_features=probe_features_RESNET_152C,probe_labels=probe_labels_RESNET_152C,\n",
        "                                          gallery_features=adversial_features_RESNET_152C,gallery_labels=adversial_labels_RESNET_152C,k=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nde2hh27qeJA",
        "outputId": "1f000cd8-52ec-4705-d9b9-513dd4e7134e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on adversial images for IR_152A is: 0.7880794701986755\n",
            "The top1 Accuracy on adversial images for IR_152C is: 0.7947019867549668\n",
            "The top1 Accuracy on adversial images for RESNET_152A is: 0.7947019867549668\n",
            "The top1 Accuracy on adversial images for RESNET_152C is: 0.7947019867549668\n"
          ]
        }
      ],
      "source": [
        "print(\"The top1 Accuracy on adversial images for IR_152A is: {}\".format(adversial_top1_accuracy_IR152A))\n",
        "print(\"The top1 Accuracy on adversial images for IR_152C is: {}\".format(adversial_top1_accuracy_IR152C))\n",
        "print(\"The top1 Accuracy on adversial images for RESNET_152A is: {}\".format(adversial_top1_accuracy_RESNET152A))\n",
        "print(\"The top1 Accuracy on adversial images for RESNET_152C is: {}\".format(adversial_top1_accuracy_RESNET152C))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlQ5ONpF5sJR",
        "outputId": "0fa30a42-1171-407e-d0ce-a42ee49b3d31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on adversial images for IR_152A is: 0.7947019867549668\n",
            "The top5 Accuracy on adversial images for IR_152C is: 0.7947019867549668\n",
            "The top5 Accuracy on adversial images for RESNET_152A is: 0.7947019867549668\n",
            "The top5 Accuracy on adversial images for RESNET_152C is: 0.8013245033112583\n"
          ]
        }
      ],
      "source": [
        "print(\"The top5 Accuracy on adversial images for IR_152A is: {}\".format(adversial_top5_accuracy_IR152A))\n",
        "print(\"The top5 Accuracy on adversial images for IR_152C is: {}\".format(adversial_top5_accuracy_IR152C))\n",
        "print(\"The top5 Accuracy on adversial images for RESNET_152A is: {}\".format(adversial_top5_accuracy_RESNET152A))\n",
        "print(\"The top5 Accuracy on adversial images for RESNET_152C is: {}\".format(adversial_top5_accuracy_RESNET152C))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gallery_images_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/gallery1_features/gallery_images_IR_152A.npy\")\n",
        "probe_images_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/probe1_features/probe_images_IR_152A.npy\")\n",
        "adversial_images_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/adversial1_features/adversial_images_IR_152A.npy\")"
      ],
      "metadata": {
        "id": "g41Zgv25sq1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26gLdfVfyNcU",
        "outputId": "10ef2440-5668-41b4-e1c9-3f255724704c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img 1 is: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/gallery/Aaron_Eckhart/Aaron_Eckhart_105_83.jpeg \n",
            "img 2 is: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/probe/Aaron_Eckhart/Aaron_Eckhart_257_176.jpeg \n",
            "IR_152 ArcFace score is : 0.7413190771717567\n",
            "IR_152 CosFace score is : 0.6754996214791376\n",
            "RESNET_152 ArcFace score is : 0.7050748316227949\n",
            "RESNET_152 CosFace score is : 0.7014041057537382\n"
          ]
        }
      ],
      "source": [
        "print(\"img 1 is: {} \".format(gallery_images_IR_152A[0]))\n",
        "print(\"img 2 is: {} \".format(probe_images_IR_152A[1]))\n",
        "\n",
        "score_IR152A = cosine_similarity(gallery_features_IR_152A[0],probe_features_IR_152A[1])\n",
        "print(\"IR_152 ArcFace score is : {}\".format(score_IR152A))\n",
        "\n",
        "score_IR152C = cosine_similarity(gallery_features_IR_152C[0],probe_features_IR_152C[1])\n",
        "print(\"IR_152 CosFace score is : {}\".format(score_IR152C))\n",
        "\n",
        "score_RES152A = cosine_similarity(gallery_features_RESNET_152A[0],probe_features_RESNET_152A[1])\n",
        "print(\"RESNET_152 ArcFace score is : {}\".format(score_RES152A))\n",
        "\n",
        "score_RES152C = cosine_similarity(gallery_features_RESNET_152C[0],probe_features_RESNET_152C[1])\n",
        "print(\"RESNET_152 CosFace score is : {}\".format(score_RES152C))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Oizmqpv5_DR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3af10f4-5161-409f-94cf-9cef73643ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "img 1 is: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_galleries/adversial_gallery_ensemble/Aaron_Eckhart/Aaron_Eckhart_105_83.jpeg \n",
            "img 2 is: /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/probe/Aaron_Eckhart/Aaron_Eckhart_257_176.jpeg \n",
            "IR_152 ArcFace score is : 0.7413190771717567\n",
            "IR_152 CosFace score is : 0.6754996214791376\n",
            "RESNET_152 ArcFace score is : 0.7050748316227949\n",
            "RESNET_152 CosFace score is : 0.7014041057537382\n"
          ]
        }
      ],
      "source": [
        "print(\"img 1 is: {} \".format(adversial_images_IR_152A[0]))\n",
        "print(\"img 2 is: {} \".format(probe_images_IR_152A[1]))\n",
        "\n",
        "score_IR152A = cosine_similarity(adversial_features_IR_152A[0],probe_features_IR_152A[1])\n",
        "print(\"IR_152 ArcFace score is : {}\".format(score_IR152A))\n",
        "\n",
        "score_IR152C = cosine_similarity(adversial_features_IR_152C[0],probe_features_IR_152C[1])\n",
        "print(\"IR_152 CosFace score is : {}\".format(score_IR152C))\n",
        "\n",
        "score_RES152A = cosine_similarity(adversial_features_RESNET_152A[0],probe_features_RESNET_152A[1])\n",
        "print(\"RESNET_152 ArcFace score is : {}\".format(score_RES152A))\n",
        "\n",
        "score_RES152C = cosine_similarity(adversial_features_RESNET_152C[0],probe_features_RESNET_152C[1])\n",
        "print(\"RESNET_152 CosFace score is : {}\".format(score_RES152C))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(probe_features_IR_152A[11],adversial_features_IR_152A,probe_labels_IR_152A[11],gallery_labels_IR_152A,n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEO3kEcVzTrz",
        "outputId": "b1c0d405-4042-4fba-f99f-89bdfb07af85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(probe_features_IR_152A[11],adversial_features_IR_152A,probe_labels_IR_152A[11],gallery_labels_IR_152A,n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3k7orZXzUXT",
        "outputId": "d084c5c1-9e52-43d7-8c48-ebcc0f72406a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probe_images_IR_152A[15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FFymVmwjzYJJ",
        "outputId": "d38d14b2-e584-4d0c-a21f-cd5296e01301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/probe/Adam_Brody/Adam_Brody_720_431.jpeg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApmG12ixzfF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkHFbY1wzWmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8g86QwjYNST",
        "outputId": "d4245b02-6f75-4c55-ac57-c17c81dab289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------+\n",
            "|                                        Evaluation pipeline Top 1                                        |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|         Attacker        |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|   clean_images_gallery  | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |\n",
            "| Ensemble_attack_gallery | 78.80794701986756 | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tableEvaluation = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation.title = 'Evaluation pipeline Top 1'\n",
        "tableEvaluation.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation.add_row(['clean_images_gallery',clean_top1_accuracy_IR152A*100,clean_top1_accuracy_IR152C*100,clean_top1_accuracy_RESNET152A*100,clean_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation.add_row(['Ensemble_attack_gallery',adversial_top1_accuracy_IR152A*100,adversial_top1_accuracy_IR152C*100, adversial_top1_accuracy_RESNET152A*100,adversial_top1_accuracy_RESNET152C*100])\n",
        "\n",
        "print(tableEvaluation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuMWsc6basFx",
        "outputId": "56d0af1c-da90-4e26-9de6-45495a77b01a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------+\n",
            "|                                        Evaluation pipeline Top 5                                        |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|         Attacker        |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|   clean_images_gallery  | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |       100.0       |\n",
            "| Ensemble_attack_gallery | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 | 80.13245033112582 |\n",
            "+-------------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tableEvaluation2 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation2.title = 'Evaluation pipeline Top 5'\n",
        "tableEvaluation2.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation2.add_row(['clean_images_gallery', clean_top5_accuracy_IR152A*100,clean_top5_accuracy_IR152C*100,clean_top5_accuracy_RESNET152A*100,clean_top5_accuracy_RESNET152C*100])\n",
        "tableEvaluation2.add_row(['Ensemble_attack_gallery',adversial_top5_accuracy_IR152A*100,adversial_top5_accuracy_IR152C*100, adversial_top5_accuracy_RESNET152A*100,adversial_top5_accuracy_RESNET152C*100])\n",
        "\n",
        "print(tableEvaluation2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Now Lets Check accuracy by attacking 5 identities and computing accuracy against their corresponding probe for all models\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oob7FwpRDFDn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNGbej5SheEd"
      },
      "outputs": [],
      "source": [
        "# Okay now lets check the accuracy w.r.t to only adversial gallery and its corresponding probe\n",
        "lowkey_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery' #90% of validation data\n",
        "lowkey_probe_root = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe\"\n",
        "\n",
        "# Generate Dataset\n",
        "lowkey_gallery_dataset = datasets.ImageFolder(lowkey_gallery_root, transform)\n",
        "lowkey_probe_dataset = datasets.ImageFolder(lowkey_probe_root, transform)\n",
        "\n",
        "# Generate loader with batch size = 16\n",
        "lowkey_gallery_loader = torch.utils.data.DataLoader(lowkey_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n",
        "lowkey_probe_loader = torch.utils.data.DataLoader(lowkey_probe_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets make loader for the corresponding probes for all attack\n",
        "#Probe features with IR_152\n",
        "all_attack_probe_labels_IR_152A,all_attack_probe_images_IR_152A,all_attack_probe_features_IR_152A = extract_feature_face(loader=lowkey_probe_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_IR_152A.npy\",all_attack_probe_labels_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_images_IR_152A.npy\",all_attack_probe_images_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_IR_152A.npy\",all_attack_probe_features_IR_152A)\n",
        "\n",
        "#Probe features with IR_152C\n",
        "all_attack_probe_labels_IR_152C,all_attack_probe_images_IR_152C,all_attack_probe_features_IR_152C = extract_feature_face(loader=lowkey_probe_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_IR_152C.npy\",all_attack_probe_labels_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_images_IR_152C.npy\",all_attack_probe_images_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_IR_152C.npy\",all_attack_probe_features_IR_152C)\n",
        "\n",
        "#Probe features with RESNET_152A\n",
        "all_attack_probe_labels_RESNET_152A,all_attack_probe_images_RESNET_152A,all_attack_probe_features_RESNET_152A = extract_feature_face(loader=lowkey_probe_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_RESNET_152A.npy\",all_attack_probe_labels_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_images_RESNET_152A.npy\",all_attack_probe_images_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_RESNET_152A.npy\",all_attack_probe_features_RESNET_152A)\n",
        "\n",
        "#Probe features with RESNET_152C\n",
        "all_attack_probe_labels_RESNET_152C,all_attack_probe_images_RESNET_152C,all_attack_probe_features_RESNET_152C = extract_feature_face(loader=lowkey_probe_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_RESNET_152C.npy\",all_attack_probe_labels_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_images_RESNET_152C.npy\",all_attack_probe_images_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_RESNET_152C.npy\",all_attack_probe_features_RESNET_152C)\n",
        "\n"
      ],
      "metadata": {
        "id": "7_HPL1BTEEMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cbe7ad0-ec13-4b8b-9a96-7219c14e66dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 5\n",
            "============================================================\n",
            "Features zeros shape: (35, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (35, 512)\n",
            "Number of Classes: 5\n",
            "============================================================\n",
            "Features zeros shape: (35, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (35, 512)\n",
            "Number of Classes: 5\n",
            "============================================================\n",
            "Features zeros shape: (35, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (35, 512)\n",
            "Number of Classes: 5\n",
            "============================================================\n",
            "Features zeros shape: (35, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (35, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (35, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Lets do it for new Work\n",
        "# #Load labels for IR_152A\n",
        "# all_attack_probe_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_IR_152A.npy\")\n",
        "# all_attack_probe_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_IR_152A.npy\")\n",
        "\n",
        "# #Load labels for IR_152C\n",
        "# all_attack_probe_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_IR_152C.npy\")\n",
        "# all_attack_probe_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_IR_152C.npy\")\n",
        "\n",
        "# #Load labels for RESNET_152A\n",
        "# all_attack_probe_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_RESNET_152A.npy\")\n",
        "# all_attack_probe_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_RESNET_152A.npy\")\n",
        "\n",
        "# #Load labels for RESNET_152C\n",
        "# all_attack_probe_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_labels_RESNET_152C.npy\")\n",
        "# all_attack_probe_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe_features/all_attack_probe_features_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "BkD1sG5wUJnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pfcw1i1mQGi",
        "outputId": "f417063b-d8d7-44df-c678-b11dbd21411b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1240, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1240, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1240, 512)\n"
          ]
        }
      ],
      "source": [
        "# Generate Ensemble attacked Gallery features\n",
        "from matplotlib.patches import Arc\n",
        "#Lets extract features for IR_152A\n",
        "lowkey_gallery_labels_IR_152A,lowkey_gallery_images_IR_152A,lowkey_gallery_features_IR_152A = extract_feature_face(loader=lowkey_gallery_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_IR_152A.npy\", lowkey_gallery_labels_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_images_IR_152A.npy\", lowkey_gallery_images_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_IR_152A.npy\", lowkey_gallery_features_IR_152A)\n",
        "\n",
        "#Extract gallery features for IR_152C\n",
        "lowkey_gallery_labels_IR_152C,lowkey_gallery_images_IR_152C,lowkey_gallery_features_IR_152C = extract_feature_face(loader=lowkey_gallery_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_IR_152C.npy\", lowkey_gallery_labels_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_images_IR_152C.npy\", lowkey_gallery_images_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_IR_152C.npy\", lowkey_gallery_features_IR_152C)\n",
        "\n",
        "#Extract gallery features for  RESNET_152A\n",
        "lowkey_gallery_labels_RESNET_152A,lowkey_gallery_images_RESNET_152A,lowkey_gallery_features_RESNET_152A = extract_feature_face(loader=lowkey_gallery_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_RESNET_152A.npy\", lowkey_gallery_labels_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_images_RESNET_152A.npy\", lowkey_gallery_images_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_RESNET_152A.npy\", lowkey_gallery_features_RESNET_152A)\n",
        "\n",
        "#extract gallery features for RESNET_152C\n",
        "lowkey_gallery_labels_RESNET_152C,lowkey_gallery_images_RESNET_152C,lowkey_gallery_features_RESNET_152C = extract_feature_face(loader=lowkey_gallery_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_RESNET_152C.npy\", lowkey_gallery_labels_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_images_RESNET_152C.npy\", lowkey_gallery_images_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_RESNET_152C.npy\", lowkey_gallery_features_RESNET_152C)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XpRSLuGpcas"
      },
      "outputs": [],
      "source": [
        "#Lets do it for new Work\n",
        "#Load labels for IR_152A\n",
        "lowkey_gallery_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_IR_152A.npy\")\n",
        "lowkey_gallery_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_IR_152A.npy\")\n",
        "\n",
        "#Load labels for IR_152C\n",
        "lowkey_gallery_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_IR_152C.npy\")\n",
        "lowkey_gallery_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_IR_152C.npy\")\n",
        "\n",
        "#Load labels for RESNET_152A\n",
        "lowkey_gallery_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_RESNET_152A.npy\")\n",
        "lowkey_gallery_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_RESNET_152A.npy\")\n",
        "\n",
        "#Load labels for RESNET_152C\n",
        "lowkey_gallery_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_labels_RESNET_152C.npy\")\n",
        "lowkey_gallery_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery_features/lowkey_gallery_features_RESNET_152C.npy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR_fbIhDqDaB",
        "outputId": "9afc0276-7ad4-419e-e791-218a30bb0ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 94.04it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 74.37it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 84.72it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 93.98it/s]\n"
          ]
        }
      ],
      "source": [
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "lowkey_top1_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=lowkey_gallery_features_IR_152A,\n",
        "                                          gallery_labels=lowkey_gallery_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "lowkey_top1_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=lowkey_gallery_features_IR_152C,\n",
        "                                          gallery_labels=lowkey_gallery_labels_IR_152C,k=1)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "lowkey_top1_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=lowkey_gallery_features_RESNET_152A,\n",
        "                                          gallery_labels=lowkey_gallery_labels_RESNET_152A,k=1)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "lowkey_top1_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=lowkey_gallery_features_RESNET_152C,\n",
        "                                          gallery_labels=lowkey_gallery_labels_RESNET_152C,k=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV9X53g9rJ5Z",
        "outputId": "b2a75606-a4ac-4a6a-becc-4df952fba457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on lowkey images for IR_152A is: 0.0%\n",
            "The top1 Accuracy on lowkey images for IR_152C is: 0.0%\n",
            "The top1 Accuracy on lowkey images for RESNET_152A is: 0.0%\n",
            "The top1 Accuracy on lowkey images for RESNET_152C is: 0.0%\n"
          ]
        }
      ],
      "source": [
        "print(\"The top1 Accuracy on lowkey images for IR_152A is: {}%\".format(lowkey_top1_accuracy_IR152A *100))\n",
        "print(\"The top1 Accuracy on lowkey images for IR_152C is: {}%\".format(lowkey_top1_accuracy_IR152C *100))\n",
        "print(\"The top1 Accuracy on lowkey images for RESNET_152A is: {}%\".format(lowkey_top1_accuracy_RESNET152A *100))\n",
        "print(\"The top1 Accuracy on lowkey images for RESNET_152C is: {}%\".format(lowkey_top1_accuracy_RESNET152C *100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX39wlAjB7Uw",
        "outputId": "ad03b9c2-eef6-41f6-dee9-2bc6aaca3bef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 52.06it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 92.18it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 93.79it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 100.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "lowkey_top5_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=lowkey_gallery_features_IR_152A,\n",
        "                                          gallery_labels=lowkey_gallery_labels_IR_152A,k=3)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "lowkey_top5_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=lowkey_gallery_features_IR_152C,\n",
        "                                          gallery_labels=lowkey_gallery_labels_IR_152C,k=3)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "lowkey_top5_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=lowkey_gallery_features_RESNET_152A,\n",
        "                                          gallery_labels=lowkey_gallery_labels_RESNET_152A,k=3)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "lowkey_top5_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=lowkey_gallery_features_RESNET_152C,\n",
        "                                          gallery_labels=lowkey_gallery_labels_RESNET_152C,k=3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KceOZfxbCKhd",
        "outputId": "973f3104-76e0-462e-9655-9d8502537383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on lowkey images for IR_152A is: 0.0%\n",
            "The top5 Accuracy on lowkey images for IR_152C is: 2.857142857142857%\n",
            "The top5 Accuracy on lowkey images for RESNET_152A is: 8.571428571428571%\n",
            "The top5 Accuracy on lowkey images for RESNET_152C is: 5.714285714285714%\n"
          ]
        }
      ],
      "source": [
        "print(\"The top5 Accuracy on lowkey images for IR_152A is: {}%\".format(lowkey_top5_accuracy_IR152A *100))\n",
        "print(\"The top5 Accuracy on lowkey images for IR_152C is: {}%\".format(lowkey_top5_accuracy_IR152C *100))\n",
        "print(\"The top5 Accuracy on lowkey images for RESNET_152A is: {}%\".format(lowkey_top5_accuracy_RESNET152A *100))\n",
        "print(\"The top5 Accuracy on lowkey images for RESNET_152C is: {}%\".format(lowkey_top5_accuracy_RESNET152C *100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpT2Q6y8EfN7",
        "outputId": "0e8c1aa8-9ee0-43a3-9972-b890bbb982b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------+\n",
            "|                                     Evaluation pipeline Top 1                                     |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|      Attacker     |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|   clean_Gallery   | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |\n",
            "| Adversial_Gallery | 78.80794701986756 | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 |\n",
            "|  Lowkey_attack_5  |        0.0        |        0.0        |        0.0        |        0.0        |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tableEvaluation4 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation4.title = 'Evaluation pipeline Top 1'\n",
        "tableEvaluation4.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation4.add_row(['clean_Gallery', clean_top1_accuracy_IR152A*100,clean_top1_accuracy_IR152C*100,clean_top1_accuracy_RESNET152A*100,clean_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation4.add_row(['Adversial_Gallery',adversial_top1_accuracy_IR152A*100,adversial_top1_accuracy_IR152C*100, adversial_top1_accuracy_RESNET152A*100,adversial_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation4.add_row(['Lowkey_attack_5',lowkey_top1_accuracy_IR152A *100,lowkey_top1_accuracy_IR152C *100, lowkey_top1_accuracy_RESNET152A *100,lowkey_top1_accuracy_RESNET152C *100])\n",
        "\n",
        "print(tableEvaluation4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evcePcB7sn4q",
        "outputId": "a0a24c02-dee5-4de7-8a75-65d623c5e781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------+\n",
            "|                                     Evaluation pipeline Top 5                                     |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|      Attacker     |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|   clean_gallery   | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |       100.0       |\n",
            "| Adversial_gallery | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 | 80.13245033112582 |\n",
            "|  Lowkey_attack_5  |        0.0        | 2.857142857142857 | 8.571428571428571 | 5.714285714285714 |\n",
            "+-------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tableEvaluation3 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation3.title = 'Evaluation pipeline Top 5'\n",
        "tableEvaluation3.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation3.add_row(['clean_gallery', clean_top5_accuracy_IR152A*100,clean_top5_accuracy_IR152C*100,clean_top5_accuracy_RESNET152A*100,clean_top5_accuracy_RESNET152C*100])\n",
        "tableEvaluation3.add_row(['Adversial_gallery',adversial_top5_accuracy_IR152A*100,adversial_top5_accuracy_IR152C*100, adversial_top5_accuracy_RESNET152A*100,adversial_top5_accuracy_RESNET152C*100])\n",
        "tableEvaluation3.add_row(['Lowkey_attack_5',lowkey_top5_accuracy_IR152A *100,lowkey_top5_accuracy_IR152C *100, lowkey_top5_accuracy_RESNET152A *100,lowkey_top5_accuracy_RESNET152C *100])\n",
        "\n",
        "print(tableEvaluation3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(all_attack_probe_features_IR_152A[9],lowkey_gallery_features_IR_152A,all_attack_probe_labels_IR_152A[9],lowkey_gallery_labels_IR_152A,n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKLDM9pqznl0",
        "outputId": "1c2fa5be-237d-4212-c597-041e175ac685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best_match(all_attack_probe_features_IR_152A[9],lowkey_gallery_features_IR_152A,all_attack_probe_labels_IR_152A[9],lowkey_gallery_labels_IR_152A,n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GQWgTLdz3yY",
        "outputId": "2e62ac32-4a36-4782-fa5b-94936829dd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_attack_probe_images_IR_152A[9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3xFqPWK9z6UW",
        "outputId": "e1b74a1d-9640-45be-8b16-ea547d72c766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/probe/Alfred_Molina/Alfred_Molina_4116_2485.jpeg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Avdd6-CN0QkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQiafnke0HKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNcu9MIR0FWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FNdZ4AMMz_bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Now Lets Perform attack on gallery with  IR_152 Arc Face model\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yhohfosjIA6L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvbi5aq11L2G"
      },
      "outputs": [],
      "source": [
        "IR_152_attack_id_1 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody\"\n",
        "IR_152_attack_id_2 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina\"\n",
        "IR_152_attack_id_3 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia\"\n",
        "IR_152_attack_id_4 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis\"\n",
        "IR_152_attack_id_5 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAgYwkaG-fh1"
      },
      "outputs": [],
      "source": [
        "#Create model lists to be used with Lowkey protect_dir folder as Lowkey takes models in form of lists\n",
        "model_IR_152A_list =[]\n",
        "model_IR_152C_list =[]\n",
        "model_RESNET_152A_list =[]\n",
        "model_RESNET_152C_list =[]\n",
        "\n",
        "model_IR_152A_list.append(IR_152A)\n",
        "model_IR_152C_list.append(IR_152C)\n",
        "model_RESNET_152A_list.append(RESNET_152A)\n",
        "model_RESNET_152C_list.append(RESNET_152C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "af9897863f4f4cc297f703150628a2a3",
            "355a0e3ef6624af0b58e0c8ca42fd414",
            "887e7d07863643f0a8c2690752cdc3df",
            "70fd88c0b2e843c4a17c9e96acc2eddf",
            "8dd501db6934417ebf626bec247a569b",
            "abcacddd65654d4fad7f9900691955d8",
            "3eed707e84dc43199719e5ac5a1b3f74",
            "b649c80e2742466bbbc7e69a5321611e",
            "836333dc9d2e435a8903e572565caeee",
            "b502139e69534d11a7e28a782ed32015",
            "1717def1ecbb45c3b23553916e5136b4"
          ]
        },
        "id": "LhPVzXtr1qhr",
        "outputId": "9015808a-282d-4fba-86ff-d67d58745c06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/69 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_700_427.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af9897863f4f4cc297f703150628a2a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 1/69 [00:09<11:01,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_635_398.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/69 [00:18<10:17,  9.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_619_386.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 3/69 [00:27<10:00,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_650_405.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 4/69 [00:36<09:45,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_630_395.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 5/69 [00:45<09:39,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_687_422.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 6/69 [00:54<09:27,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_620_387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 7/69 [01:03<09:16,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_651_406.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 8/69 [01:12<09:11,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_644_402.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 9/69 [01:21<08:59,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_657_408.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 10/69 [01:30<08:58,  9.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_681_418.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 11/69 [01:41<09:17,  9.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_592_371.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 12/69 [01:50<08:59,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_610_381.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 13/69 [01:59<08:39,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_600_374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 14/69 [02:08<08:24,  9.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_686_421.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 15/69 [02:17<08:14,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_632_396.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 16/69 [02:26<07:58,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_722_432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 17/69 [02:35<07:43,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_636_399.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 18/69 [02:43<07:34,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_659_409.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 19/69 [02:52<07:23,  8.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_616_384.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 20/69 [03:01<07:14,  8.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_603_377.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 21/69 [03:10<07:08,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_522_339.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 22/69 [03:19<07:01,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_495_322.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 23/69 [03:28<06:54,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_601_375.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 24/69 [03:37<06:45,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_529_342.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 25/69 [03:46<06:38,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_506_328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 26/69 [03:55<06:27,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_471_308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 27/69 [04:04<06:17,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_491_320.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 28/69 [04:13<06:07,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_604_378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 29/69 [04:25<06:27,  9.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_508_330.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 30/69 [04:34<06:08,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_487_318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 31/69 [04:42<05:51,  9.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_460_302.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 32/69 [04:51<05:39,  9.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_570_365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 33/69 [05:00<05:26,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_480_311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 34/69 [05:09<05:15,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_542_349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 35/69 [05:18<05:05,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_518_336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 36/69 [05:27<04:55,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_621_388.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 37/69 [05:36<04:45,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_450_295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 38/69 [05:45<04:36,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_469_307.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 39/69 [05:54<04:28,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_475_310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 40/69 [06:02<04:18,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_586_369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 41/69 [06:11<04:09,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_554_356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 42/69 [06:21<04:03,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_530_343.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 43/69 [06:29<03:53,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_564_362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 44/69 [06:38<03:44,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_567_363.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 45/69 [06:47<03:35,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_683_419.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 46/69 [06:56<03:26,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_445_293.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 47/69 [07:05<03:17,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_379_249.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 48/69 [07:17<03:27,  9.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_364_240.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 49/69 [07:26<03:12,  9.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_398_260.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 50/69 [07:35<02:58,  9.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_435_287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 51/69 [07:44<02:46,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_360_238.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 52/69 [07:53<02:36,  9.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_427_282.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 53/69 [08:02<02:25,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_486_317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 54/69 [08:11<02:16,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_355_235.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 55/69 [08:20<02:07,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_395_258.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 56/69 [08:29<01:57,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_405_264.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 57/69 [08:38<01:48,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_374_246.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 58/69 [08:47<01:39,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_371_244.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 59/69 [08:56<01:30,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_391_254.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 60/69 [09:05<01:21,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_485_316.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 61/69 [09:15<01:12,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_426_281.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|████████▉ | 62/69 [09:24<01:03,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_422_277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 63/69 [09:33<00:54,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_394_257.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 64/69 [09:42<00:45,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_440_290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 65/69 [09:51<00:36,  9.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_409_267.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 66/69 [10:00<00:27,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_375_247.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 67/69 [10:11<00:19,  9.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_428_283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▊| 68/69 [10:21<00:09,  9.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Adam_Brody/Adam_Brody_411_269.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [10:30<00:00,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# #Lets attack the directories with IR_152ArcFace of models to compute adversial attack\n",
        "# protect_dir(dirs_root=IR_152_attack_id_1,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e7eQYF1M5l0X",
        "outputId": "6fcbcb18-f8cf-4f92-96d6-abf448cffb0a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4224_2548.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/43 [00:09<06:27,  9.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4271_2575.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 2/43 [00:18<06:14,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4201_2532.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 3/43 [00:27<06:02,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4284_2580.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 4/43 [00:36<05:53,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4203_2534.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 5/43 [00:45<05:43,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4057_2449.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 6/43 [00:54<05:31,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4030_2431.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▋        | 7/43 [01:05<05:56,  9.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4008_2416.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▊        | 8/43 [01:14<05:35,  9.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4125_2491.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 9/43 [01:23<05:19,  9.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4191_2525.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 10/43 [01:33<05:07,  9.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4109_2483.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 11/43 [01:42<04:55,  9.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4028_2429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 12/43 [01:51<04:43,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4014_2420.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 13/43 [01:59<04:32,  9.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4052_2444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 14/43 [02:09<04:23,  9.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4170_2514.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 15/43 [02:18<04:13,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4067_2457.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 16/43 [02:26<04:03,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4007_2415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 17/43 [02:35<03:54,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3996_2406.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|███▉      | 17/43 [02:36<03:59,  9.23s/it]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-5547e780cf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprotect_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIR_152_attack_id_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_IR_152A_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-39c855731c76>\u001b[0m in \u001b[0;36mprotect_dir\u001b[0;34m(dirs_root, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-39c855731c76>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_2,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDaTy_MQFXkC",
        "outputId": "c0d1ef19-5284-4eab-b654-9e9d65c8ffde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3959_2378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 1/25 [00:09<03:36,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4078_2467.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 2/25 [00:17<03:24,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4207_2536.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 3/25 [00:26<03:17,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2453.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 4/25 [00:35<03:09,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4032_2433.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 5/25 [00:44<02:58,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4053_2445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 6/25 [00:53<02:49,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2454.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 7/25 [01:05<02:56,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4214_2543.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 8/25 [01:14<02:41,  9.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3997_2407.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 9/25 [01:22<02:28,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3938_2360.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 10/25 [01:31<02:18,  9.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3971_2387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 11/25 [01:40<02:07,  9.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3943_2365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 12/25 [01:49<01:57,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3977_2392.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 13/25 [01:58<01:48,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3940_2362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 14/25 [02:07<01:39,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3994_2404.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 15/25 [02:16<01:29,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3942_2364.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 16/25 [02:25<01:20,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4096_2477.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 17/25 [02:34<01:11,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3975_2390.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 18/25 [02:43<01:02,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4009_2417.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 19/25 [02:52<00:53,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4002_2412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 20/25 [03:01<00:44,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3957_2376.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 21/25 [03:10<00:35,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3947_2369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 22/25 [03:18<00:26,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3939_2361.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 23/25 [03:28<00:17,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3952_2372.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 24/25 [03:36<00:08,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3944_2366.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [03:45<00:00,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_2,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FItNacMlD7_z",
        "outputId": "63d198fe-59c2-4237-cf82-714d3d8dfc7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/69 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5271_3034.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|▏         | 1/69 [00:10<11:25, 10.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5253_3022.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/69 [00:18<10:29,  9.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5262_3028.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 3/69 [00:27<10:04,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5249_3019.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 4/69 [00:37<10:19,  9.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5226_3001.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 5/69 [00:46<09:54,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5246_3017.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 6/69 [00:55<09:37,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5265_3029.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 7/69 [01:04<09:25,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5233_3008.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 8/69 [01:13<09:12,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5294_3049.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 9/69 [01:22<08:59,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5281_3043.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 10/69 [01:32<09:06,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5237_3011.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 11/69 [01:41<08:51,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5270_3033.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 12/69 [01:50<08:39,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5250_3020.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 13/69 [01:59<08:28,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5193_2976.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 14/69 [02:08<08:14,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5228_3003.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 15/69 [02:17<08:05,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5184_2968.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 16/69 [02:28<08:33,  9.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5190_2973.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▍       | 17/69 [02:37<08:13,  9.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5176_2961.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 18/69 [02:46<07:53,  9.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5133_2933.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 19/69 [02:55<07:37,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5094_2904.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 20/69 [03:04<07:26,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5054_2871.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 21/69 [03:12<07:13,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5148_2943.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 22/69 [03:21<07:02,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5058_2875.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 23/69 [03:30<06:51,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5178_2962.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 24/69 [03:39<06:42,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5132_2932.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 25/69 [03:48<06:32,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5201_2983.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 26/69 [03:57<06:21,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5162_2951.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 27/69 [04:06<06:17,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5118_2921.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 28/69 [04:15<06:07,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5091_2902.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 29/69 [04:24<05:56,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5149_2944.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 30/69 [04:33<05:47,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5167_2956.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▍     | 31/69 [04:42<05:39,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5199_2982.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▋     | 32/69 [04:51<05:30,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5101_2910.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 33/69 [04:59<05:21,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5090_2901.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 34/69 [05:09<05:14,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5227_3002.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 35/69 [05:18<05:13,  9.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5128_2929.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 36/69 [05:28<05:12,  9.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5082_2894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▎    | 37/69 [05:37<04:58,  9.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4972_2800.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 38/69 [05:46<04:45,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5055_2872.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 39/69 [05:55<04:33,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4967_2796.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 40/69 [06:06<04:36,  9.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5002_2829.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 41/69 [06:16<04:30,  9.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4995_2822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 42/69 [06:25<04:16,  9.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5037_2856.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 43/69 [06:34<04:03,  9.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5045_2864.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 44/69 [06:43<03:51,  9.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4981_2809.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 45/69 [06:52<03:39,  9.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5079_2891.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 45/69 [06:53<03:40,  9.18s/it]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-f0d303e4d5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprotect_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIR_152_attack_id_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_IR_152A_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-39c855731c76>\u001b[0m in \u001b[0;36mprotect_dir\u001b[0;34m(dirs_root, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-39c855731c76>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_3,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKnr1v3QHTCX",
        "outputId": "a367065e-8271-4d6b-8098-806ec58efc96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/23 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5048_2867.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 1/23 [00:09<03:23,  9.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5034_2853.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▊         | 2/23 [00:18<03:12,  9.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4992_2820.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 3/23 [00:27<02:59,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5019_2843.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 4/23 [00:35<02:48,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5006_2833.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 5/23 [00:44<02:40,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5052_2869.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 6/23 [00:53<02:31,  8.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4975_2803.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 7/23 [01:02<02:22,  8.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4983_2811.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 35%|███▍      | 8/23 [01:11<02:14,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4999_2826.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 9/23 [01:20<02:05,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5040_2859.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 10/23 [01:29<01:56,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4996_2823.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 11/23 [01:38<01:47,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5003_2830.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 12/23 [01:47<01:38,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5050_2868.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 13/23 [01:56<01:29,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4979_2807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 14/23 [02:05<01:20,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4977_2805.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 15/23 [02:14<01:11,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5053_2870.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|██████▉   | 16/23 [02:24<01:04,  9.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5023_2845.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 17/23 [02:33<00:55,  9.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4966_2795.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 18/23 [02:44<00:48,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4962_2792.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 19/23 [02:53<00:38,  9.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5046_2865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 20/23 [03:02<00:28,  9.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4961_2791.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████▏| 21/23 [03:11<00:18,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4960_2790.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 22/23 [03:20<00:09,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4959_2789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 23/23 [03:29<00:00,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_3,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG31Ltj_D8ui",
        "outputId": "52a4ae23-e109-4a29-f21a-b37888dee5fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5844_3393.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/50 [00:08<07:16,  8.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5935_3444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 2/50 [00:18<07:14,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5880_3415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 3/50 [00:27<07:05,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5911_3435.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 4/50 [00:35<06:52,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5896_3424.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 5/50 [00:44<06:43,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5918_3439.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 6/50 [00:53<06:35,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5871_3411.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 7/50 [01:02<06:24,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5903_3429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 8/50 [01:11<06:17,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5908_3432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 9/50 [01:20<06:09,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5875_3412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 10/50 [01:29<06:00,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5956_3451.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 11/50 [01:38<05:50,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5904_3430.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 12/50 [01:47<05:41,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5914_3436.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 13/50 [01:56<05:31,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5793_3359.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 14/50 [02:05<05:22,  8.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5974_3459.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 15/50 [02:17<05:42,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5689_3311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 16/50 [02:26<05:25,  9.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5707_3321.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 17/50 [02:35<05:08,  9.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5740_3336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 18/50 [02:44<04:54,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5869_3410.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 19/50 [02:53<04:45,  9.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5701_3318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 20/50 [03:02<04:35,  9.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5790_3356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 21/50 [03:11<04:25,  9.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5726_3329.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 22/50 [03:20<04:16,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5738_3335.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 23/50 [03:29<04:06,  9.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5762_3345.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 24/50 [03:38<03:55,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5792_3358.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 25/50 [03:47<03:45,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5664_3295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 26/50 [03:56<03:36,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5720_3327.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 27/50 [04:05<03:26,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5725_3328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 28/50 [04:14<03:17,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5657_3291.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 29/50 [04:23<03:09,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5737_3334.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 30/50 [04:32<03:00,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5772_3349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 31/50 [04:41<02:50,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5700_3317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 32/50 [04:50<02:41,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5688_3310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 33/50 [04:59<02:32,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5813_3374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 34/50 [05:08<02:23,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5782_3354.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 35/50 [05:19<02:23,  9.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5936_3445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 36/50 [05:28<02:11,  9.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5751_3340.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 37/50 [05:37<02:00,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5697_3315.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 38/50 [05:46<01:49,  9.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5634_3273.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 39/50 [05:55<01:40,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5648_3283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 40/50 [06:04<01:30,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5651_3286.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 41/50 [06:13<01:21,  9.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5641_3279.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 42/50 [06:22<01:12,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5685_3308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 43/50 [06:31<01:02,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5656_3290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 44/50 [06:39<00:53,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5666_3296.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 45/50 [06:48<00:44,  8.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5639_3277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 46/50 [06:57<00:35,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5677_3304.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 47/50 [07:06<00:26,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5635_3274.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 48/50 [07:15<00:17,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5652_3287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 49/50 [07:24<00:08,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5640_3278.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [07:33<00:00,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_4,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I-3MKcsJ-9W",
        "outputId": "9462ce04-6252-4d77-a66d-f87b44cb9670"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/64 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8812_4907.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/64 [00:10<10:50, 10.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8794_4894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 2/64 [00:19<09:48,  9.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8782_4885.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  5%|▍         | 3/64 [00:28<09:22,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8809_4905.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▋         | 4/64 [00:37<09:09,  9.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8551_4729.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 5/64 [00:46<08:54,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8718_4842.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 6/64 [00:54<08:42,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8571_4741.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 7/64 [01:03<08:32,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8588_4752.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 8/64 [01:12<08:23,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8734_4854.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 9/64 [01:21<08:14,  8.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8814_4909.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 10/64 [01:31<08:07,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8749_4863.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 11/64 [01:40<08:00,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8680_4814.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 12/64 [01:49<07:47,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8689_4822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 13/64 [01:58<07:39,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8687_4821.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 14/64 [02:07<07:32,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8576_4744.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 15/64 [02:16<07:21,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8824_4916.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 16/64 [02:26<07:25,  9.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8564_4738.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 17/64 [02:35<07:12,  9.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8708_4835.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 18/64 [02:44<06:59,  9.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8751_4865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|██▉       | 19/64 [02:53<06:49,  9.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8781_4884.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 31%|███▏      | 20/64 [03:04<07:17,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8568_4740.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 21/64 [03:13<06:55,  9.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8810_4906.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 22/64 [03:23<06:37,  9.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8760_4873.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 23/64 [03:32<06:22,  9.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8619_4773.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 24/64 [03:41<06:10,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8703_4831.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 25/64 [03:50<05:58,  9.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8670_4807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 26/64 [03:59<05:47,  9.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8641_4789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 27/64 [04:08<05:35,  9.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8648_4793.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 28/64 [04:17<05:25,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8697_4828.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 29/64 [04:25<05:15,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8746_4860.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 30/64 [04:34<05:04,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8802_4898.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 31/64 [04:43<04:56,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8496_4684.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 32/64 [04:52<04:47,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8522_4703.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 33/64 [05:01<04:40,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8526_4706.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 34/64 [05:11<04:31,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8563_4737.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 35/64 [05:20<04:21,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8470_4669.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 56%|█████▋    | 36/64 [05:29<04:12,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8477_4673.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 37/64 [05:38<04:04,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8456_4657.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 38/64 [05:47<03:54,  9.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8572_4742.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 39/64 [05:56<03:46,  9.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8779_4882.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 40/64 [06:07<03:53,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8486_4681.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 41/64 [06:16<03:40,  9.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8549_4727.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 42/64 [06:25<03:26,  9.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8519_4700.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 43/64 [06:34<03:13,  9.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8539_4718.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 44/64 [06:43<03:03,  9.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8518_4699.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 45/64 [06:52<02:53,  9.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8607_4765.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 46/64 [07:01<02:43,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8480_4676.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 47/64 [07:10<02:34,  9.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8525_4705.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 48/64 [07:19<02:24,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8462_4663.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 49/64 [07:28<02:15,  9.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8681_4815.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 50/64 [07:37<02:05,  9.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8617_4771.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|███████▉  | 51/64 [07:46<01:57,  9.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8508_4691.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 81%|████████▏ | 52/64 [07:55<01:48,  9.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8557_4733.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 53/64 [08:04<01:39,  9.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8566_4739.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 54/64 [08:13<01:29,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8586_4750.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 55/64 [08:22<01:20,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8479_4675.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 56/64 [08:31<01:11,  8.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8511_4694.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 57/64 [08:40<01:02,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8537_4716.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 58/64 [08:49<00:53,  8.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8556_4732.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 59/64 [08:58<00:44,  8.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8603_4762.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 60/64 [09:09<00:38,  9.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8461_4662.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 61/64 [09:18<00:28,  9.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8476_4672.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 62/64 [09:27<00:18,  9.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 63/64 [09:36<00:09,  9.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8471_4670.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [09:46<00:00,  9.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152_attack_id_5,model=model_IR_152A_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets define a loader for IR_152_attacked gallery\n",
        "IR_152A_attack_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery' #90% of validation data\n",
        "# Generate Dataset\n",
        "IR_152A_attack_gallery_dataset = datasets.ImageFolder(IR_152A_attack_gallery_root, transform)\n",
        "# Generate loader with batch size = 16\n",
        "IR_152A_attack_gallery_loader = torch.utils.data.DataLoader(IR_152A_attack_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n"
      ],
      "metadata": {
        "id": "wVSXqUpES9SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets generate the features for IR_152A_attacked identities\n",
        "from matplotlib.patches import Arc\n",
        "#Lets extract features for IR_152A\n",
        "attack_IR152A_labels_IR_152A,attack_IR152A_images_IR_152A,attack_IR152A_features_IR_152A = extract_feature_face(loader=IR_152A_attack_gallery_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_IR_152A.npy\", attack_IR152A_labels_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__images_IR_152A.npy\", attack_IR152A_images_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_IR_152A.npy\", attack_IR152A_features_IR_152A)\n",
        "\n",
        "#Lets extract features for IR_152C\n",
        "attack_IR152A_labels_IR_152C,attack_IR152A_images_IR_152C,attack_IR152A_features_IR_152C = extract_feature_face(loader=IR_152A_attack_gallery_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_IR_152C.npy\", attack_IR152A_labels_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__images_IR_152C.npy\", attack_IR152A_images_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_IR_152C.npy\", attack_IR152A_features_IR_152C)\n",
        "\n",
        "#Lets extract features for RESNET_152A\n",
        "attack_IR152A_labels_RESNET_152A,attack_IR152A_images_RESNET_152A,attack_IR152A_features_RESNET_152A = extract_feature_face(loader=IR_152A_attack_gallery_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_RESNET_152A.npy\", attack_IR152A_labels_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__images_RESNET_152A.npy\", attack_IR152A_images_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_RESNET_152A.npy\", attack_IR152A_features_RESNET_152A)\n",
        "\n",
        "#extract gallery features for RESNET_152C\n",
        "\n",
        "attack_IR152A_labels_RESNET_152C,attack_IR152A_images_RESNET_152C,attack_IR152A_features_RESNET_152C = extract_feature_face(loader=IR_152A_attack_gallery_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_RESNET_152C.npy\", attack_IR152A_labels_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__images_RESNET_152C.npy\", attack_IR152A_images_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_RESNET_152C.npy\", attack_IR152A_features_RESNET_152C)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FTJb3GXV2PU",
        "outputId": "b1e01044-a989-4600-a2c4-7fcd7e59ce41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create the loader for these directories\n",
        "attack_IR152A_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_IR_152A.npy\")\n",
        "attack_IR152A_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_IR_152A.npy\")\n",
        "\n",
        "attack_IR152A_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_IR_152C.npy\")\n",
        "attack_IR152A_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_IR_152C.npy\")\n",
        "\n",
        "\n",
        "attack_IR152A_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_RESNET_152A.npy\")\n",
        "attack_IR152A_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_RESNET_152A.npy\")\n",
        "\n",
        "attack_IR152A_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__labels_RESNET_152C.npy\")\n",
        "attack_IR152A_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery_features/attack_IR152A__features_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "K5NLkQQFY4A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "IR_152A_attack_top1_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_IR152A_features_IR_152A,\n",
        "                                          gallery_labels=attack_IR152A_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "IR_152A_attack_top1_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_IR152A_features_IR_152C,\n",
        "                                          gallery_labels=attack_IR152A_labels_IR_152C,k=1)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "IR_152A_attack_top1_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_IR152A_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_IR152A_labels_RESNET_152A,k=1)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "IR_152A_attack_top1_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_IR152A_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_IR152A_labels_RESNET_152C,k=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGqJLFZzZyv4",
        "outputId": "9adb8577-4cb4-45b5-f02d-51f547f65cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 88.14it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 90.93it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 94.90it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 90.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top1 Accuracy on IR_152A_attacked identity images for IR_152A is: {}%\".format(IR_152A_attack_top1_accuracy_IR152A *100))\n",
        "print(\"The top1 Accuracy on IR_152A_attacked identity images for IR_152C is: {}%\".format(IR_152A_attack_top1_accuracy_IR152C *100))\n",
        "print(\"The top1 Accuracy on IR_152A_attacked identity images for RESNET_152A is: {}%\".format(IR_152A_attack_top1_accuracy_RESNET152A *100))\n",
        "print(\"The top1 Accuracy on IR_152A_attacked identity images for RESNET_152C is: {}%\".format(IR_152A_attack_top1_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6qBr3PCbl4p",
        "outputId": "edf6c366-f299-4d53-aec6-61cf8ada86fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on IR_152A_attacked identity images for IR_152A is: 0.0%\n",
            "The top1 Accuracy on IR_152A_attacked identity images for IR_152C is: 0.0%\n",
            "The top1 Accuracy on IR_152A_attacked identity images for RESNET_152A is: 0.0%\n",
            "The top1 Accuracy on IR_152A_attacked identity images for RESNET_152C is: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "IR_152A_attack_top5_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_IR152A_features_IR_152A,\n",
        "                                          gallery_labels=attack_IR152A_labels_IR_152A,k=3)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "IR_152A_attack_top5_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_IR152A_features_IR_152C,\n",
        "                                          gallery_labels=attack_IR152A_labels_IR_152C,k=3)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "IR_152A_attack_top5_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_IR152A_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_IR152A_labels_RESNET_152A,k=3)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "IR_152A_attack_top5_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_IR152A_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_IR152A_labels_RESNET_152C,k=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIIsgcgqcaIe",
        "outputId": "24a4d3b1-0111-40c4-ddd5-b576bb8354bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:01<00:00, 31.79it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 56.67it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 53.61it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 45.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top5 Accuracy on IR_152A_attacked identity images for IR_152A is: {}%\".format(IR_152A_attack_top5_accuracy_IR152A *100))\n",
        "print(\"The top5 Accuracy on IR_152A_attacked identity images for IR_152C is: {}%\".format(IR_152A_attack_top5_accuracy_IR152C *100))\n",
        "print(\"The top5 Accuracy on IR_152A_attacked identity images for RESNET_152A is: {}%\".format(IR_152A_attack_top5_accuracy_RESNET152A *100))\n",
        "print(\"The top5 Accuracy on IR_152A_attacked identity images for RESNET_152C is: {}%\".format(IR_152A_attack_top5_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUFS8D19cnaW",
        "outputId": "1a84d764-85b5-4a2a-a391-05bbbd6a071c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on IR_152A_attacked identity images for IR_152A is: 0.0%\n",
            "The top5 Accuracy on IR_152A_attacked identity images for IR_152C is: 0.0%\n",
            "The top5 Accuracy on IR_152A_attacked identity images for RESNET_152A is: 0.0%\n",
            "The top5 Accuracy on IR_152A_attacked identity images for RESNET_152C is: 2.857142857142857%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Now lets do attack with IR_152 CosFace for 5 directories and compute top1 and top5\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0gAGrS4lKofB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4UmIkklKsRr"
      },
      "outputs": [],
      "source": [
        "# Now lets do attack on IR_152 C for 5 directories\n",
        "IR_152C_attack_id_1 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody\"\n",
        "IR_152C_attack_id_2 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina\"\n",
        "IR_152C_attack_id_3 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia\"\n",
        "IR_152C_attack_id_4 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis\"\n",
        "IR_152C_attack_id_5 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcluruWynSOk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "67cd109a27de42939e73961f94ae6b9a",
            "de88dac9aea74354abfa8f9250b51998",
            "12ffe4823b1a4618b10641856daed088",
            "985cb0aebd9b49f49b410c1179463a2e",
            "92ee5771e1e547ff965caf7f11bc7fde",
            "32ec514336cc417cb0269075763b6ae9",
            "2fe13ed52e7b484f850760c26a56d2c7",
            "752709f260234bf987b232cc4fdb44b0",
            "b22bab584a28488cb9ec5d19c9a77917",
            "f65eb8fa5a06406eb5604b81eab78724",
            "090a5a4276e14a88a7f627781f831d6a"
          ]
        },
        "outputId": "63c3f821-85d6-442c-9454-47db31f1e135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/69 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_592_371.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67cd109a27de42939e73961f94ae6b9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/69 [00:13<15:40, 13.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_610_381.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/69 [00:23<12:37, 11.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_722_432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/69 [00:31<11:02, 10.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_644_402.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/69 [00:41<10:47,  9.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_657_408.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/69 [00:50<10:05,  9.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_630_395.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/69 [00:59<09:44,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_651_406.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/69 [01:07<09:23,  9.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_616_384.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/69 [01:21<10:36, 10.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_700_427.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/69 [01:31<10:26, 10.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_687_422.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/69 [01:41<10:03, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_620_387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/69 [01:49<09:22,  9.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_636_399.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/69 [01:58<08:56,  9.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_635_398.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/69 [02:09<09:07,  9.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_632_396.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/69 [02:18<08:50,  9.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_681_418.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/69 [02:28<08:45,  9.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_619_386.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/69 [02:38<08:45,  9.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_600_374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 17/69 [02:48<08:28,  9.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_686_421.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/69 [02:57<08:03,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_650_405.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/69 [03:05<07:41,  9.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_659_409.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/69 [03:15<07:35,  9.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_506_328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/69 [03:26<07:48,  9.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_487_318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/69 [03:37<08:06, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_621_388.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/69 [03:49<08:13, 10.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_508_330.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 24/69 [04:02<08:27, 11.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_491_320.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/69 [04:11<07:54, 10.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_495_322.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/69 [04:21<07:33, 10.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_601_375.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 27/69 [04:33<07:34, 10.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_450_295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/69 [04:45<07:38, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_518_336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 29/69 [04:54<07:08, 10.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_529_342.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/69 [05:04<06:49, 10.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_570_365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 31/69 [05:15<06:46, 10.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_460_302.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 32/69 [05:25<06:23, 10.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_480_311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 33/69 [05:34<05:53,  9.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_471_308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 34/69 [05:45<05:59, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_530_343.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 35/69 [05:56<06:02, 10.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_469_307.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 36/69 [06:07<05:47, 10.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_564_362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 37/69 [06:20<06:07, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_542_349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 38/69 [06:30<05:40, 10.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_554_356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/69 [06:41<05:27, 10.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_522_339.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 40/69 [06:52<05:15, 10.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_604_378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 41/69 [07:02<04:59, 10.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_567_363.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 42/69 [07:11<04:32, 10.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_475_310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 43/69 [07:19<04:10,  9.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_603_377.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 44/69 [07:29<03:59,  9.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_586_369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 45/69 [07:40<04:03, 10.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_683_419.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 46/69 [07:49<03:46,  9.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_360_238.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 47/69 [08:04<04:07, 11.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_426_281.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 48/69 [08:17<04:07, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_379_249.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 49/69 [08:26<03:42, 11.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_395_258.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 50/69 [08:35<03:16, 10.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_435_287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 51/69 [08:44<02:56,  9.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_355_235.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 52/69 [08:52<02:40,  9.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_440_290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 53/69 [09:01<02:27,  9.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_485_316.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 54/69 [09:10<02:19,  9.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_394_257.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 55/69 [09:19<02:07,  9.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_375_247.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 56/69 [09:27<01:55,  8.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_428_283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 57/69 [09:36<01:45,  8.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_374_246.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 58/69 [09:44<01:35,  8.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_405_264.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 59/69 [09:53<01:25,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_371_244.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 60/69 [10:01<01:16,  8.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_411_269.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 61/69 [10:09<01:07,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_486_317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 62/69 [10:18<00:59,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_364_240.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 63/69 [10:26<00:50,  8.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_422_277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 64/69 [10:35<00:42,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_427_282.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 65/69 [10:43<00:33,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_409_267.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 66/69 [10:52<00:25,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_445_293.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 67/69 [11:00<00:16,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_391_254.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 68/69 [11:09<00:08,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Adam_Brody/Adam_Brody_398_260.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [11:17<00:00,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_1,model=model_IR_152C_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_2,model=model_IR_152C_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F5i9pu_yfdm3",
        "outputId": "6915dbe3-5f4c-43ca-d36c-2faa64cab61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/43 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4203_2534.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/43 [00:08<05:54,  8.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4271_2575.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 2/43 [00:17<05:51,  8.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4201_2532.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 3/43 [00:25<05:41,  8.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4224_2548.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 4/43 [00:40<07:04, 10.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4284_2580.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 5/43 [00:50<06:43, 10.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4053_2445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 6/43 [01:02<06:49, 11.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3997_2407.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▋        | 7/43 [01:10<06:07, 10.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4030_2431.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▊        | 8/43 [01:19<05:46,  9.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4007_2415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 9/43 [01:28<05:21,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2454.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 10/43 [01:36<05:01,  9.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4170_2514.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 11/43 [01:45<04:46,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4032_2433.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 12/43 [01:53<04:31,  8.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4057_2449.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 13/43 [02:02<04:21,  8.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4207_2536.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 14/43 [02:11<04:20,  8.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4078_2467.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 15/43 [02:21<04:13,  9.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2453.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 16/43 [02:30<04:09,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4014_2420.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 17/43 [02:42<04:23, 10.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4067_2457.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 18/43 [02:54<04:22, 10.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4109_2483.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 19/43 [03:02<03:57,  9.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3996_2406.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 19/43 [03:03<03:51,  9.64s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-132-a5ab0a1f02b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprotect_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIR_152C_attack_id_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_IR_152C_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-c9841f84f93f>\u001b[0m in \u001b[0;36mprotect_dir\u001b[0;34m(dirs_root, model)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-c9841f84f93f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m## Detects facial points ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfacial5points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print(\"The value for _ in detect faces is {} end \".format(facial5points))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mb_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfacial5points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_2,model=model_IR_152C_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLdwIEwJkiMB",
        "outputId": "44751492-49e5-4ad4-df42-77249828390a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/23 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4028_2429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 1/23 [00:08<03:09,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4191_2525.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 2/23 [00:17<03:07,  8.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4008_2416.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 3/23 [00:26<02:55,  8.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4052_2444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 4/23 [00:36<02:59,  9.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4125_2491.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 5/23 [00:48<03:03, 10.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3959_2378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 6/23 [01:00<03:04, 10.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4214_2543.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 7/23 [01:12<03:00, 11.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3977_2392.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 8/23 [01:21<02:37, 10.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3952_2372.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 9/23 [01:31<02:22, 10.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3994_2404.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 10/23 [01:39<02:07,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3947_2369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 11/23 [01:52<02:07, 10.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3939_2361.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 12/23 [02:06<02:08, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4096_2477.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 13/23 [02:18<01:57, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3944_2366.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 14/23 [02:27<01:39, 11.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4009_2417.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 15/23 [02:36<01:22, 10.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4002_2412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 16/23 [02:44<01:08,  9.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3975_2390.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 17/23 [02:54<00:58,  9.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3942_2364.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 18/23 [03:05<00:51, 10.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3938_2360.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 19/23 [03:15<00:40, 10.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3943_2365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 20/23 [03:27<00:32, 10.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3957_2376.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 21/23 [03:37<00:20, 10.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3940_2362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 22/23 [03:46<00:09,  9.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3971_2387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23/23 [03:56<00:00, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_3,model=model_IR_152C_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Or9LeXVffoJ",
        "outputId": "99068ea9-9b45-4a9b-a588-2b95cd3645cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5193_2976.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/68 [00:12<13:58, 12.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5226_3001.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/68 [00:22<12:18, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5262_3028.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/68 [00:31<10:46,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5271_3034.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/68 [00:39<10:02,  9.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5294_3049.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/68 [00:48<09:31,  9.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5250_3020.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/68 [00:56<09:12,  8.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5228_3003.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/68 [01:05<09:05,  8.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5253_3022.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/68 [01:18<10:02, 10.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5265_3029.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/68 [01:33<11:26, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5270_3033.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 10/68 [01:44<11:08, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5237_3011.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/68 [01:54<10:22, 10.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5249_3019.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 12/68 [02:05<10:23, 11.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5233_3008.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/68 [02:15<09:45, 10.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5246_3017.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 14/68 [02:24<09:07, 10.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5281_3043.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/68 [02:33<08:35,  9.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5058_2875.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 16/68 [02:47<09:31, 10.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5128_2929.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 17/68 [02:57<09:06, 10.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5133_2933.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 18/68 [03:06<08:38, 10.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5167_2956.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/68 [03:19<08:59, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5184_2968.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/68 [03:32<09:18, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5149_2944.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 21/68 [03:43<09:00, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5201_2983.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/68 [03:52<08:09, 10.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5132_2932.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 23/68 [04:00<07:30, 10.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5091_2902.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 24/68 [04:09<07:11,  9.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5199_2982.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 25/68 [04:18<06:46,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5101_2910.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/68 [04:27<06:26,  9.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5118_2921.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 27/68 [04:35<06:10,  9.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5082_2894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/68 [04:45<06:11,  9.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5162_2951.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 29/68 [04:55<06:03,  9.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5094_2904.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 30/68 [05:05<06:11,  9.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5178_2962.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 31/68 [05:16<06:04,  9.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5054_2871.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 32/68 [05:27<06:13, 10.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5176_2961.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 33/68 [05:36<05:51, 10.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5090_2901.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 34/68 [05:45<05:27,  9.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5190_2973.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 35/68 [05:54<05:07,  9.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5148_2943.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 36/68 [06:03<04:57,  9.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5227_3002.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 37/68 [06:12<04:43,  9.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5045_2864.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 38/68 [06:20<04:30,  9.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4967_2796.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/68 [06:30<04:29,  9.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5040_2859.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 40/68 [06:41<04:29,  9.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4999_2826.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 41/68 [06:51<04:22,  9.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5053_2870.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 42/68 [07:01<04:17,  9.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4972_2800.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 43/68 [07:12<04:15, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4996_2823.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 44/68 [07:23<04:14, 10.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5019_2843.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 45/68 [07:34<04:05, 10.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4966_2795.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 46/68 [07:45<03:58, 10.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4992_2820.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 47/68 [07:54<03:34, 10.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4975_2803.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 48/68 [08:08<03:44, 11.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4977_2805.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 49/68 [08:18<03:26, 10.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5003_2830.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 50/68 [08:28<03:12, 10.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4983_2811.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 51/68 [08:37<02:50, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5034_2853.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 52/68 [08:46<02:36,  9.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4981_2809.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 53/68 [08:57<02:32, 10.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5002_2829.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 54/68 [09:10<02:35, 11.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5048_2867.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 55/68 [09:19<02:14, 10.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4979_2807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 56/68 [09:27<01:57,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5006_2833.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 57/68 [09:38<01:51, 10.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5055_2872.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 58/68 [09:49<01:44, 10.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5050_2868.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 59/68 [10:01<01:36, 10.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4995_2822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 60/68 [10:11<01:25, 10.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5052_2869.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 61/68 [10:21<01:12, 10.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5023_2845.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 62/68 [10:29<00:58,  9.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5037_2856.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 63/68 [10:38<00:47,  9.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4959_2789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 64/68 [10:49<00:39,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5046_2865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 65/68 [11:01<00:31, 10.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4962_2792.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 66/68 [11:13<00:22, 11.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4961_2791.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 67/68 [11:22<00:10, 10.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4960_2790.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [11:31<00:00, 10.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_4,model=model_IR_152C_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-N3AcseVfhH_",
        "outputId": "3c3528bd-8e08-4dbf-8e1c-0c4fefc9cae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5896_3424.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:13<11:11, 13.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5904_3430.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:25<10:13, 12.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5908_3432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:38<09:54, 12.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5880_3415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:48<08:53, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5974_3459.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:56<07:53, 10.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5956_3451.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [01:05<07:13,  9.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5844_3393.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [01:14<06:46,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5935_3444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [01:22<06:26,  9.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5875_3412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [01:31<06:09,  9.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5918_3439.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [01:40<05:58,  8.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5903_3429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [01:52<06:30, 10.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5914_3436.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [02:04<06:38, 10.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5793_3359.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [02:18<07:09, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5871_3411.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [02:29<06:51, 11.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5911_3435.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [02:38<06:19, 10.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5813_3374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [02:49<06:02, 10.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5726_3329.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [02:58<05:41, 10.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5689_3311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [03:07<05:15,  9.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5700_3317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [03:16<04:55,  9.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5936_3445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [03:29<05:15, 10.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5688_3310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [03:38<04:55, 10.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5740_3336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [03:47<04:31,  9.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5772_3349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [03:55<04:13,  9.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5790_3356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [04:04<03:58,  9.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5738_3335.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [04:16<04:11, 10.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5869_3410.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [04:28<04:14, 10.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5762_3345.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [04:39<04:07, 10.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5725_3328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [04:50<03:57, 10.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5707_3321.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [05:02<03:53, 11.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5701_3318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [05:14<03:48, 11.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5664_3295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [05:23<03:26, 10.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5720_3327.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [05:35<03:18, 11.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5782_3354.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [05:47<03:11, 11.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5737_3334.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [05:55<02:47, 10.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5792_3358.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [06:04<02:29,  9.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5657_3291.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [06:14<02:19,  9.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5697_3315.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [06:24<02:09,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5751_3340.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [06:32<01:54,  9.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5685_3308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [06:42<01:45,  9.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5651_3286.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [06:57<01:52, 11.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5648_3283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [07:06<01:33, 10.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5635_3274.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [07:15<01:19,  9.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5666_3296.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [07:23<01:06,  9.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5640_3278.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [07:33<00:57,  9.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5641_3279.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [07:42<00:47,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5634_3273.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [07:54<00:40, 10.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5652_3287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [08:04<00:30, 10.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5656_3290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [08:14<00:20, 10.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5677_3304.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [08:22<00:09,  9.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5639_3277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [08:31<00:00, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=IR_152C_attack_id_5,model=model_IR_152C_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5SoEL7tfizH",
        "outputId": "639cd3af-f38d-459e-92da-fb18a9b939f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/64 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8812_4907.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/64 [00:09<10:16,  9.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8794_4894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/64 [00:22<12:07, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8809_4905.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/64 [00:34<11:40, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8782_4885.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/64 [00:43<10:43, 10.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8781_4884.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/64 [00:53<10:19, 10.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8648_4793.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/64 [01:06<10:45, 11.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8680_4814.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/64 [01:18<10:55, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8571_4741.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 8/64 [01:29<10:46, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8687_4821.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/64 [01:39<10:03, 10.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8619_4773.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/64 [01:51<10:06, 11.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8718_4842.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/64 [02:02<09:57, 11.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8746_4860.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/64 [02:14<09:49, 11.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8588_4752.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 13/64 [02:22<08:54, 10.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8689_4822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/64 [02:31<08:12,  9.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8760_4873.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 15/64 [02:39<07:44,  9.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8697_4828.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/64 [02:49<07:42,  9.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8641_4789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/64 [03:00<07:51, 10.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8551_4729.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 18/64 [03:11<07:53, 10.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8708_4835.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 19/64 [03:22<07:54, 10.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8824_4916.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 20/64 [03:33<07:43, 10.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8802_4898.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/64 [03:46<08:01, 11.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8703_4831.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 22/64 [03:58<08:06, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8568_4740.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 23/64 [04:08<07:37, 11.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8576_4744.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/64 [04:18<07:11, 10.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8734_4854.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 25/64 [04:27<06:38, 10.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8751_4865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 26/64 [04:38<06:34, 10.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8810_4906.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 27/64 [04:48<06:22, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8670_4807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/64 [04:58<06:12, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8814_4909.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 29/64 [05:09<06:08, 10.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8564_4738.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 30/64 [05:19<05:49, 10.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8749_4863.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 31/64 [05:28<05:23,  9.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8603_4762.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 32/64 [05:38<05:14,  9.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8508_4691.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/64 [05:46<04:53,  9.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8539_4718.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 34/64 [05:56<04:42,  9.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8566_4739.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 35/64 [06:07<04:52, 10.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8470_4669.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 36/64 [06:18<04:51, 10.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8462_4663.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 37/64 [06:27<04:25,  9.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8511_4694.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 38/64 [06:35<04:05,  9.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8556_4732.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 39/64 [06:44<03:51,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8496_4684.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 40/64 [06:54<03:46,  9.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8486_4681.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 41/64 [07:03<03:30,  9.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8519_4700.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 42/64 [07:11<03:17,  8.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8586_4750.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 43/64 [07:20<03:06,  8.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8537_4716.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 44/64 [07:28<02:55,  8.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8557_4733.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 45/64 [07:37<02:45,  8.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8617_4771.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 46/64 [07:46<02:36,  8.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8456_4657.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 47/64 [07:54<02:27,  8.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8607_4765.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 48/64 [08:03<02:18,  8.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8572_4742.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 49/64 [08:13<02:17,  9.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8477_4673.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 50/64 [08:26<02:23, 10.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8681_4815.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 51/64 [08:38<02:20, 10.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8525_4705.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 52/64 [08:51<02:17, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8480_4676.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 53/64 [09:05<02:15, 12.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8563_4737.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 54/64 [09:14<01:52, 11.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8779_4882.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 55/64 [09:25<01:39, 11.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8518_4699.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 56/64 [09:39<01:36, 12.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8479_4675.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 57/64 [09:51<01:23, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8549_4727.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 58/64 [10:04<01:13, 12.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8526_4706.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 59/64 [10:13<00:57, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8522_4703.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 60/64 [10:23<00:44, 11.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8461_4662.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 61/64 [10:32<00:30, 10.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8471_4670.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 62/64 [10:41<00:19,  9.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 63/64 [10:51<00:10, 10.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8476_4672.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [11:00<00:00, 10.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets define a loader for IR_152_ C attacked gallery\n",
        "IR_152C_attack_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery' #90% of validation data\n",
        "# Generate Dataset\n",
        "IR_152C_attack_gallery_dataset = datasets.ImageFolder(IR_152C_attack_gallery_root, transform)\n",
        "\n",
        "# Generate loader with batch size = 16\n",
        "IR_152C_attack_gallery_loader = torch.utils.data.DataLoader(IR_152C_attack_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n"
      ],
      "metadata": {
        "id": "6xWZfULff8SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Lets generate the features for IR_152C_attacked identities\n",
        "# from matplotlib.patches import Arc\n",
        "# #Lets extract features for IR_152A\n",
        "# attack_IR152C_labels_IR_152A,attack_IR152C_images_IR_152A,attack_IR152C_features_IR_152A = extract_feature_face(loader=IR_152C_attack_gallery_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_IR_152A.npy\", attack_IR152C_labels_IR_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__images_IR_152A.npy\", attack_IR152C_images_IR_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_IR_152A.npy\", attack_IR152C_features_IR_152A)\n",
        "\n",
        "# #Lets extract features for IR_152C\n",
        "# attack_IR152C_labels_IR_152C,attack_IR152C_images_IR_152C,attack_IR152C_features_IR_152C = extract_feature_face(loader=IR_152C_attack_gallery_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_IR_152C.npy\", attack_IR152C_labels_IR_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__images_IR_152C.npy\", attack_IR152C_images_IR_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_IR_152C.npy\", attack_IR152C_features_IR_152C)\n",
        "\n",
        "# #Lets extract features for RESNET_152A\n",
        "# attack_IR152C_labels_RESNET_152A,attack_IR152C_images_RESNET_152A,attack_IR152C_features_RESNET_152A = extract_feature_face(loader=IR_152C_attack_gallery_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_RESNET_152A.npy\", attack_IR152C_labels_RESNET_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__images_RESNET_152A.npy\", attack_IR152C_images_RESNET_152A)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_RESNET_152A.npy\", attack_IR152C_features_RESNET_152A)\n",
        "\n",
        "# #extract gallery features for RESNET_152C\n",
        "\n",
        "# attack_IR152C_labels_RESNET_152C,attack_IR152C_images_RESNET_152C,attack_IR152C_features_RESNET_152C = extract_feature_face(loader=IR_152C_attack_gallery_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_RESNET_152C.npy\", attack_IR152C_labels_RESNET_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__images_RESNET_152C.npy\", attack_IR152C_images_RESNET_152C)\n",
        "# np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_RESNET_152C.npy\", attack_IR152C_features_RESNET_152C)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y6H1AmQfpgf",
        "outputId": "06451da7-b492-4346-ace1-06c6516879e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create the loader for these directories\n",
        "attack_IR152C_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_IR_152A.npy\")\n",
        "attack_IR152C_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_IR_152A.npy\")\n",
        "\n",
        "attack_IR152C_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_IR_152C.npy\")\n",
        "attack_IR152C_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_IR_152C.npy\")\n",
        "\n",
        "\n",
        "attack_IR152C_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_RESNET_152A.npy\")\n",
        "attack_IR152C_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_RESNET_152A.npy\")\n",
        "\n",
        "attack_IR152C_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__labels_RESNET_152C.npy\")\n",
        "attack_IR152C_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery_features/attack_IR152C__features_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "0I20AnzRoeje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "IR_152C_attack_top1_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_IR152C_features_IR_152A,\n",
        "                                          gallery_labels=attack_IR152C_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "IR_152C_attack_top1_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_IR152C_features_IR_152C,\n",
        "                                          gallery_labels=attack_IR152C_labels_IR_152C,k=1)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "IR_152C_attack_top1_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_IR152C_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_IR152C_labels_RESNET_152A,k=1)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "IR_152C_attack_top1_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_IR152C_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_IR152C_labels_RESNET_152C,k=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqz2_Z5AhKfP",
        "outputId": "573043b2-5048-4dde-e592-3bf74f1b3c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 78.12it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 58.76it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 93.84it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 83.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "IR_152C_attack_top5_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_IR152C_features_IR_152A,\n",
        "                                          gallery_labels=attack_IR152C_labels_IR_152A,k=3)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "IR_152C_attack_top5_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_IR152C_features_IR_152C,\n",
        "                                          gallery_labels=attack_IR152C_labels_IR_152C,k=3)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "IR_152C_attack_top5_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_IR152C_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_IR152C_labels_RESNET_152A,k=3)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "IR_152C_attack_top5_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_IR152C_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_IR152C_labels_RESNET_152C,k=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGyFBaD4hfVg",
        "outputId": "694abcbd-7bf7-418f-cad5-b62fef8cf349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 72.09it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 54.27it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 93.16it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 99.82it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top1 Accuracy on IR_152C_attacked identity images for IR_152A is: {}%\".format(IR_152C_attack_top1_accuracy_IR152A *100))\n",
        "print(\"The top1 Accuracy on IR_152C_attacked identity images for IR_152C is: {}%\".format(IR_152C_attack_top1_accuracy_IR152C *100))\n",
        "print(\"The top1 Accuracy on IR_152C_attacked identity images for RESNET_152A is: {}%\".format(IR_152C_attack_top1_accuracy_RESNET152A *100))\n",
        "print(\"The top1 Accuracy on IR_152C_attacked identity images for RESNET_152C is: {}%\".format(IR_152C_attack_top1_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iHMIInIiok_",
        "outputId": "8339c76b-afc3-450e-a6b8-0414a8146f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on IR_152C_attacked identity images for IR_152A is: 0.0%\n",
            "The top1 Accuracy on IR_152C_attacked identity images for IR_152C is: 0.0%\n",
            "The top1 Accuracy on IR_152C_attacked identity images for RESNET_152A is: 2.857142857142857%\n",
            "The top1 Accuracy on IR_152C_attacked identity images for RESNET_152C is: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top5 Accuracy on IR_152C_attacked identity images for IR_152A is: {}%\".format(IR_152C_attack_top5_accuracy_IR152A *100))\n",
        "print(\"The top5 Accuracy on IR_152C_attacked identity images for IR_152C is: {}%\".format(IR_152C_attack_top5_accuracy_IR152C *100))\n",
        "print(\"The top5 Accuracy on IR_152C_attacked identity images for RESNET_152A is: {}%\".format(IR_152C_attack_top5_accuracy_RESNET152A *100))\n",
        "print(\"The top5 Accuracy on IR_152C_attacked identity images for RESNET_152C is: {}%\".format(IR_152C_attack_top5_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPRf6wjYkpvH",
        "outputId": "28344508-594d-4abb-e5be-6f42459b85be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on IR_152C_attacked identity images for IR_152A is: 0.0%\n",
            "The top5 Accuracy on IR_152C_attacked identity images for IR_152C is: 0.0%\n",
            "The top5 Accuracy on IR_152C_attacked identity images for RESNET_152A is: 2.857142857142857%\n",
            "The top5 Accuracy on IR_152C_attacked identity images for RESNET_152C is: 5.714285714285714%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Now Lets Perform attack with RESNET_152 ArcFace Model and compute top1 and top5 accuracy\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TzwlbO-IKyxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets attack with RESNETArcFace_152 Model\n",
        "# Now lets do attack on IR_152 C for 5 directories\n",
        "RESNET_152A_attack_id_1 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody\"\n",
        "RESNET_152A_attack_id_2 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina\"\n",
        "RESNET_152A_attack_id_3 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia\"\n",
        "RESNET_152A_attack_id_4 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis\"\n",
        "RESNET_152A_attack_id_5 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Esry5V_alcMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152A_attack_id_1,model=model_RESNET_152A_list)"
      ],
      "metadata": {
        "id": "BxCTD4Zzl7mA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da9a66ca2604463ab35d7cf1d6294b28",
            "f1f1eb7d962c4fc4b6c287cbe13d693e",
            "b0779cd417bd47c193543fb7c7724309",
            "ae06228bab744c45827fd2ad27c357a6",
            "cb017a23d53d46319fcd4a942df36126",
            "616971fe0bf44d52a68f6d387a7cf970",
            "f57bd1ae17414da388f9394fc13d5df5",
            "c3c3521d1ba841848a3b7c7782d00577",
            "7d1a9c7231e346c29c7bd6f035503139",
            "5a54e8670d984dc6afecfccfc30c498a",
            "697df47e39d54332881d0eb2941bc45c"
          ]
        },
        "outputId": "df2ee27b-06d5-42a1-8ced-733e7d171c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/69 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_686_421.jpeg\n",
            "Finding reference points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/Lowkey code/supp_material/align/first_stage.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img = Variable(torch.FloatTensor(_preprocess(img)), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:81: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/detector.py:102: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  img_boxes = Variable(torch.FloatTensor(img_boxes), volatile = True)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/get_nets.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  a = F.softmax(a)\n",
            "/content/drive/MyDrive/Lowkey code/supp_material/align/matlab_cp2tform.py:84: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  r, _, _, _ = lstsq(X, U)\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4289: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/233M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da9a66ca2604463ab35d7cf1d6294b28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/69 [00:27<31:22, 27.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_630_395.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/69 [00:39<20:18, 18.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_687_422.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/69 [00:50<16:36, 15.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_616_384.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/69 [01:02<14:49, 13.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_636_399.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/69 [01:14<14:11, 13.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_650_405.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/69 [01:26<13:22, 12.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_722_432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/69 [01:37<12:43, 12.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_619_386.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/69 [01:49<12:13, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_644_402.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/69 [02:00<11:53, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_659_409.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/69 [02:12<11:33, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_620_387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/69 [02:23<11:15, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_592_371.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/69 [02:35<11:00, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_700_427.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/69 [02:46<10:46, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_610_381.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/69 [02:58<10:33, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_632_396.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/69 [03:09<10:20, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_635_398.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/69 [03:21<10:09, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_657_408.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 17/69 [03:33<10:14, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_681_418.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/69 [03:45<09:59, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_651_406.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/69 [03:56<09:44, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_600_374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/69 [04:08<09:30, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_621_388.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/69 [04:19<09:16, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_469_307.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/69 [04:31<09:04, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_529_342.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/69 [04:42<08:49, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_586_369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 24/69 [04:54<08:37, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_475_310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/69 [05:05<08:27, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_530_343.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/69 [05:17<08:16, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_604_378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 27/69 [05:28<08:03, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_508_330.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/69 [05:40<07:53, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_450_295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 29/69 [05:52<07:48, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_683_419.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/69 [06:03<07:32, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_491_320.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 31/69 [06:15<07:18, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_601_375.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 32/69 [06:26<07:09, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_460_302.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 33/69 [06:38<06:58, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_542_349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 34/69 [06:50<06:45, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_487_318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 35/69 [07:01<06:32, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_506_328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 36/69 [07:13<06:20, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_570_365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 37/69 [07:25<06:13, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_522_339.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 38/69 [07:36<05:57, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_554_356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/69 [07:47<05:44, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_480_311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 40/69 [08:00<05:42, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_471_308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 41/69 [08:11<05:29, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_518_336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 42/69 [08:23<05:14, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_495_322.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 43/69 [08:34<05:01, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_564_362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 44/69 [08:46<04:48, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_567_363.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 45/69 [08:57<04:35, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_603_377.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 46/69 [09:09<04:24, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_379_249.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 47/69 [09:20<04:12, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_398_260.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 48/69 [09:32<04:01, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_360_238.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 49/69 [09:43<03:49, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_445_293.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 50/69 [09:54<03:37, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_485_316.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 51/69 [10:06<03:27, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_440_290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 52/69 [10:19<03:20, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_405_264.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 53/69 [10:30<03:07, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_409_267.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 54/69 [10:42<02:54, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_371_244.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 55/69 [10:53<02:42, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_391_254.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 56/69 [11:04<02:30, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_355_235.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 57/69 [11:16<02:18, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_422_277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 58/69 [11:28<02:07, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_394_257.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 59/69 [11:39<01:55, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_375_247.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 60/69 [11:51<01:44, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_395_258.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 61/69 [12:02<01:32, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_435_287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 62/69 [12:14<01:20, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_374_246.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 63/69 [12:25<01:09, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_364_240.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 64/69 [12:38<00:58, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_427_282.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 65/69 [12:49<00:46, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_428_283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 66/69 [13:01<00:34, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_411_269.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 67/69 [13:13<00:23, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_426_281.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 68/69 [13:24<00:11, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Adam_Brody/Adam_Brody_486_317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [13:37<00:00, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152A_attack_id_2,model=model_RESNET_152A_list)"
      ],
      "metadata": {
        "id": "tVbs-muzmLoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174d155b-9221-4341-8407-9d895e91318b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/42 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4203_2534.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/42 [00:11<08:01, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4271_2575.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 2/42 [00:23<07:49, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4284_2580.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 3/42 [00:35<07:35, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4224_2548.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 4/42 [00:46<07:23, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4201_2532.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 5/42 [00:58<07:12, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4207_2536.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 6/42 [01:11<07:18, 12.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4109_2483.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 7/42 [01:23<07:00, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3997_2407.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 8/42 [01:34<06:44, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4032_2433.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 9/42 [01:46<06:28, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4191_2525.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 10/42 [01:58<06:19, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4067_2457.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 11/42 [02:10<06:08, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4125_2491.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 12/42 [02:22<05:57, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3959_2378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 13/42 [02:34<05:44, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4028_2429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 14/42 [02:45<05:29, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2453.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 15/42 [02:57<05:17, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4014_2420.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 16/42 [03:09<05:05, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4030_2431.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 17/42 [03:21<05:00, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2454.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 18/42 [03:33<04:46, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4007_2415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 19/42 [03:45<04:33, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4078_2467.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 20/42 [03:57<04:22, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4008_2416.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 21/42 [04:09<04:10, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4214_2543.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 22/42 [04:21<03:58, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4170_2514.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 23/42 [04:33<03:48, 12.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4053_2445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 24/42 [04:45<03:38, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4057_2449.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 25/42 [04:58<03:26, 12.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4052_2444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 26/42 [05:10<03:13, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3938_2360.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 27/42 [05:21<03:00, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4002_2412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 28/42 [05:35<02:52, 12.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3947_2369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 29/42 [05:46<02:37, 12.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4009_2417.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 30/42 [05:58<02:24, 12.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3977_2392.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 31/42 [06:10<02:13, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3952_2372.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 32/42 [06:22<02:00, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3971_2387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 33/42 [06:34<01:48, 12.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3994_2404.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 34/42 [06:46<01:35, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_4096_2477.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 35/42 [06:58<01:23, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3939_2361.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 36/42 [07:09<01:10, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3942_2364.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 37/42 [07:21<00:58, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3944_2366.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 38/42 [07:33<00:47, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3975_2390.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 39/42 [07:46<00:36, 12.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3943_2365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 40/42 [07:57<00:23, 11.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3957_2376.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 41/42 [08:09<00:11, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Alfred_Molina/Alfred_Molina_3940_2362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [08:21<00:00, 11.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152A_attack_id_3,model=model_RESNET_152A_list)"
      ],
      "metadata": {
        "id": "gy8klb9RmNdQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7beb2700-11e8-4ff7-bf38-e477ff1b3883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5249_3019.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/68 [00:11<13:16, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5226_3001.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/68 [00:23<13:00, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5228_3003.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/68 [00:35<12:48, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5271_3034.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/68 [00:47<12:40, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5262_3028.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/68 [00:59<12:25, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5270_3033.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/68 [01:10<12:12, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5193_2976.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/68 [01:22<12:00, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5250_3020.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/68 [01:35<12:04, 12.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5253_3022.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/68 [01:47<11:46, 11.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5246_3017.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 10/68 [01:58<11:28, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5233_3008.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/68 [02:10<11:14, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5237_3011.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 12/68 [02:22<11:00, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5294_3049.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/68 [02:34<10:53, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5281_3043.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 14/68 [02:46<10:42, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5265_3029.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/68 [02:58<10:33, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5132_2932.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 16/68 [03:10<10:27, 12.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5133_2933.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 17/68 [03:22<10:16, 12.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5091_2902.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 18/68 [03:35<10:08, 12.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5201_2983.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/68 [03:48<10:14, 12.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5128_2929.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/68 [04:01<10:07, 12.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5101_2910.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 21/68 [04:13<09:41, 12.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5149_2944.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/68 [04:25<09:21, 12.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5184_2968.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 23/68 [04:36<09:01, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5178_2962.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 24/68 [04:48<08:46, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5094_2904.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 25/68 [05:00<08:29, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5199_2982.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/68 [05:11<08:17, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5227_3002.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 27/68 [05:23<08:04, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5090_2901.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/68 [05:35<07:50, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5148_2943.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 29/68 [05:46<07:37, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5054_2871.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 30/68 [05:58<07:27, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5082_2894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 31/68 [06:10<07:18, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5058_2875.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 32/68 [06:22<07:03, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5176_2961.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 33/68 [06:33<06:48, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5162_2951.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 34/68 [06:45<06:33, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5167_2956.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 35/68 [06:56<06:22, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5118_2921.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 36/68 [07:08<06:08, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5190_2973.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 37/68 [07:19<05:59, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4972_2800.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 38/68 [07:31<05:46, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5023_2845.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/68 [07:42<05:35, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5053_2870.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 40/68 [07:54<05:22, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4967_2796.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 41/68 [08:05<05:10, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4999_2826.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 42/68 [08:18<05:07, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5037_2856.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 43/68 [08:30<04:54, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5034_2853.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 44/68 [08:41<04:41, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4983_2811.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 45/68 [08:53<04:30, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4981_2809.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 46/68 [09:04<04:16, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5002_2829.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 47/68 [09:16<04:02, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5055_2872.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 48/68 [09:27<03:51, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5048_2867.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 49/68 [09:39<03:38, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4979_2807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 50/68 [09:50<03:27, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4996_2823.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 51/68 [10:02<03:15, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5045_2864.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 52/68 [10:13<03:04, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5003_2830.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 53/68 [10:26<02:57, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4977_2805.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 54/68 [10:37<02:44, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4966_2795.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 55/68 [10:49<02:31, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5040_2859.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 56/68 [11:00<02:19, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5006_2833.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 57/68 [11:12<02:07, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4995_2822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 58/68 [11:23<01:55, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5052_2869.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 59/68 [11:35<01:43, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4975_2803.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 60/68 [11:46<01:32, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5050_2868.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 61/68 [11:58<01:20, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5019_2843.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 62/68 [12:09<01:09, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4992_2820.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 63/68 [12:21<00:57, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4961_2791.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 64/68 [12:32<00:46, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_5046_2865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 65/68 [12:45<00:35, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4959_2789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 66/68 [12:57<00:23, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4960_2790.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 67/68 [13:08<00:11, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Garcia/Andy_Garcia_4962_2792.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [13:19<00:00, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152A_attack_id_4,model=model_RESNET_152A_list)"
      ],
      "metadata": {
        "id": "C2uzRIG4mPIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513161b2-d054-40b6-a34a-c5a1404d8e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5880_3415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:11<09:20, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5911_3435.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:24<09:41, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5974_3459.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:36<09:26, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5918_3439.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:47<09:04, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5875_3412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:59<08:50, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5956_3451.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [01:10<08:34, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5935_3444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [01:22<08:21, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5871_3411.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [01:34<08:22, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5904_3430.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [01:46<08:05, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5908_3432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [01:58<07:50, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5793_3359.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [02:09<07:37, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5844_3393.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [02:21<07:23, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5914_3436.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [02:32<07:08, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5896_3424.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [02:44<06:56, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5903_3429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [02:55<06:46, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5782_3354.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [03:07<06:33, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5688_3310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [03:18<06:21, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5725_3328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [03:30<06:10, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5751_3340.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [03:42<06:00, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5740_3336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [03:54<05:57, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5657_3291.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [04:06<05:41, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5701_3318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [04:17<05:27, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5664_3295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [04:29<05:14, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5792_3358.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [04:40<05:01, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5869_3410.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [04:52<04:50, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5762_3345.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [05:04<04:39, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5772_3349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [05:15<04:27, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5726_3329.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [05:28<04:23, 11.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5707_3321.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [05:40<04:08, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5720_3327.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [05:51<03:55, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5790_3356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [06:03<03:41, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5700_3317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [06:14<03:29, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5738_3335.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [06:26<03:18, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5689_3311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [06:37<03:05, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5936_3445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [06:49<02:53, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5813_3374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [07:01<02:42, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5737_3334.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [07:12<02:31, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5697_3315.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [07:25<02:23, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5652_3287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [07:37<02:10, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5640_3278.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [07:48<01:57, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5634_3273.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [08:00<01:44, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5648_3283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [08:11<01:32, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5651_3286.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [08:23<01:21, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5641_3279.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [08:36<01:11, 11.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5685_3308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [08:47<00:59, 11.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5656_3290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [08:59<00:47, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5639_3277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [09:11<00:35, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5677_3304.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [09:23<00:23, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5666_3296.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [09:35<00:12, 12.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Andy_Serkis/Andy_Serkis_5635_3274.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [09:47<00:00, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152A_attack_id_5,model=model_RESNET_152A_list)"
      ],
      "metadata": {
        "id": "uet0uJCWmRGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "358f9bbd-ad33-4357-b0fb-0fc84f9aca51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/64 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8782_4885.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/64 [00:11<12:18, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8794_4894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/64 [00:23<12:06, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8812_4907.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/64 [00:35<12:03, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8809_4905.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/64 [00:47<11:47, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8568_4740.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/64 [00:58<11:34, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8641_4789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/64 [01:10<11:19, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8824_4916.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/64 [01:21<11:03, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8749_4863.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 8/64 [01:33<10:49, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8781_4884.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/64 [01:45<10:39, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8648_4793.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/64 [01:57<10:42, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8760_4873.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/64 [02:09<10:24, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8814_4909.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/64 [02:20<10:10, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8697_4828.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 13/64 [02:32<09:59, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8571_4741.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/64 [02:44<09:48, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8551_4729.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 15/64 [02:56<09:35, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8708_4835.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/64 [03:07<09:23, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8588_4752.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/64 [03:19<09:09, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8564_4738.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 18/64 [03:30<08:54, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8576_4744.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 19/64 [03:42<08:43, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8670_4807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 20/64 [03:55<08:46, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8734_4854.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/64 [04:06<08:29, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8802_4898.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 22/64 [04:19<08:26, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8680_4814.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 23/64 [04:30<08:07, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8746_4860.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/64 [04:42<07:53, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8689_4822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 25/64 [04:54<07:39, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8619_4773.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 26/64 [05:05<07:25, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8718_4842.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 27/64 [05:17<07:12, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8703_4831.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/64 [05:29<06:59, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8687_4821.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 29/64 [05:40<06:50, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8810_4906.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 30/64 [05:52<06:40, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8751_4865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 31/64 [06:04<06:27, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8617_4771.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 32/64 [06:16<06:19, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8477_4673.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/64 [06:28<06:07, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8566_4739.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 34/64 [06:40<05:54, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8557_4733.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 35/64 [06:51<05:41, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8480_4676.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 36/64 [07:03<05:30, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8537_4716.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 37/64 [07:15<05:17, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8681_4815.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 38/64 [07:27<05:04, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8586_4750.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 39/64 [07:38<04:52, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8556_4732.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 40/64 [07:50<04:40, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8607_4765.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 41/64 [08:01<04:27, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8522_4703.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 42/64 [08:13<04:16, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8518_4699.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 43/64 [08:26<04:10, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8779_4882.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 44/64 [08:37<03:57, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8496_4684.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 45/64 [08:49<03:45, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8486_4681.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 46/64 [09:01<03:33, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8539_4718.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 47/64 [09:13<03:20, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8563_4737.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 48/64 [09:24<03:07, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8525_4705.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 49/64 [09:36<02:55, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8526_4706.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 50/64 [09:47<02:43, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8519_4700.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 51/64 [09:59<02:31, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8508_4691.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 52/64 [10:11<02:20, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8456_4657.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 53/64 [10:22<02:08, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8511_4694.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 54/64 [10:35<01:59, 11.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8462_4663.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 55/64 [10:47<01:46, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8603_4762.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 56/64 [10:58<01:34, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8479_4675.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 57/64 [11:10<01:22, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8470_4669.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 58/64 [11:22<01:11, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8549_4727.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 59/64 [11:34<00:58, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8572_4742.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 60/64 [11:45<00:46, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8461_4662.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 61/64 [11:57<00:35, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8471_4670.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 62/64 [12:08<00:23, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 63/64 [12:20<00:11, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8476_4672.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [12:32<00:00, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets define a loader for RESNET_152_A attacked gallery\n",
        "RESNET_152A_attack_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery' #90% of validation data\n",
        "# Generate Dataset\n",
        "RESNET_152A_attack_gallery_dataset = datasets.ImageFolder(RESNET_152A_attack_gallery_root, transform)\n",
        "\n",
        "# Generate loader with batch size = 16\n",
        "RESNET_152A_attack_gallery_loader = torch.utils.data.DataLoader(RESNET_152A_attack_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n"
      ],
      "metadata": {
        "id": "dSDITZdimY6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets generate the features for IR_152C_attacked identities\n",
        "from matplotlib.patches import Arc\n",
        "#Lets extract features for IR_152A\n",
        "attack_RESNET152A_labels_IR_152A,attack_RESNET152A_images_IR_152A,attack_RESNET152A_features_IR_152A = extract_feature_face(loader=RESNET_152A_attack_gallery_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_IR_152A.npy\", attack_RESNET152A_labels_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__images_IR_152A.npy\", attack_RESNET152A_images_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_IR_152A.npy\", attack_RESNET152A_features_IR_152A)\n",
        "\n",
        "#Lets extract features for IR_152C\n",
        "attack_RESNET152A_labels_IR_152C,attack_RESNET152A_images_IR_152C,attack_RESNET152A_features_IR_152C = extract_feature_face(loader=RESNET_152A_attack_gallery_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_IR_152C.npy\", attack_RESNET152A_labels_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__images_IR_152C.npy\", attack_RESNET152A_images_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_IR_152C.npy\", attack_RESNET152A_features_IR_152C)\n",
        "\n",
        "#Lets extract features for RESNET_152A\n",
        "attack_RESNET152A_labels_RESNET_152A,attack_RESNET152A_images_RESNET_152A,attack_RESNET152A_features_RESNET_152A = extract_feature_face(loader=RESNET_152A_attack_gallery_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_RESNET_152A.npy\", attack_RESNET152A_labels_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__images_RESNET_152A.npy\", attack_RESNET152A_images_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_RESNET_152A.npy\", attack_RESNET152A_features_RESNET_152A)\n",
        "\n",
        "#extract gallery features for RESNET_152C\n",
        "\n",
        "attack_RESNET152A_labels_RESNET_152C,attack_RESNET152A_images_RESNET_152C,attack_RESNET152A_features_RESNET_152C = extract_feature_face(loader=RESNET_152A_attack_gallery_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_RESNET_152C.npy\", attack_RESNET152A_labels_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__images_RESNET_152C.npy\", attack_RESNET152A_images_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_RESNET_152C.npy\", attack_RESNET152A_features_RESNET_152C)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6FwE5RJSm0KY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f54cd7-78dc-41ca-fe71-2b4e765701e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n",
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1243, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 672\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 688\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 704\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 720\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 736\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 752\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 768\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 784\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 800\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 816\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 832\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 848\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 864\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 880\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 896\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 912\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 928\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 944\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 960\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 976\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 992\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1008\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1024\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1040\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1056\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1072\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1088\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1104\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1120\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1136\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1152\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1168\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1184\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1200\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1216\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1243, 512)\n",
            "The value of idx is : 1232\n",
            "============================================================\n",
            "idx<len now\n",
            "============================================================\n",
            "Features l2_norm else shape : (1243, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create the loader for these directories\n",
        "attack_RESNET152A_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_IR_152A.npy\")\n",
        "attack_RESNET152A_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_IR_152A.npy\")\n",
        "\n",
        "attack_RESNET152A_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_IR_152C.npy\")\n",
        "attack_RESNET152A_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_IR_152C.npy\")\n",
        "\n",
        "\n",
        "attack_RESNET152A_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_RESNET_152A.npy\")\n",
        "attack_RESNET152A_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_RESNET_152A.npy\")\n",
        "\n",
        "attack_RESNET152A_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__labels_RESNET_152C.npy\")\n",
        "attack_RESNET152A_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery_features/attack_RESNET152A__features_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "ouPPPlAUoO6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "RESNET_152A_attack_top1_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_RESNET152A_features_IR_152A,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "RESNET_152A_attack_top1_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_RESNET152A_features_IR_152C,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_IR_152C,k=1)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "RESNET_152A_attack_top1_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_RESNET152A_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_RESNET_152A,k=1)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "RESNET_152A_attack_top1_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_RESNET152A_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_RESNET_152C,k=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "FrEQAN0zp74Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95d0da8-3696-42d2-f632-9f1ee22017e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 99.90it/s] \n",
            "100%|██████████| 35/35 [00:00<00:00, 101.10it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 99.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 98.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "RESNET_152A_attack_top5_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_RESNET152A_features_IR_152A,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_IR_152A,k=3)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "RESNET_152A_attack_top5_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_RESNET152A_features_IR_152C,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_IR_152C,k=3)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "RESNET_152A_attack_top5_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_RESNET152A_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_RESNET_152A,k=3)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "RESNET_152A_attack_top5_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_RESNET152A_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_RESNET152A_labels_RESNET_152C,k=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "9eJR2WEsqa0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a865e3e2-1ca1-4dcd-962d-8b6aaa8616b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 64.48it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 58.53it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 96.25it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 97.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top1 Accuracy on RESNET_152A_attacked identity images for IR_152A is: {}%\".format(RESNET_152A_attack_top1_accuracy_IR152A *100))\n",
        "print(\"The top1 Accuracy on RESNET_152A_attacked identity images for IR_152C is: {}%\".format(RESNET_152A_attack_top1_accuracy_IR152C *100))\n",
        "print(\"The top1 Accuracy on RESNET_152A_attacked identity images for RESNET_152A is: {}%\".format(RESNET_152A_attack_top1_accuracy_RESNET152A *100))\n",
        "print(\"The top1 Accuracy on RESNET_152A_attacked identity images for RESNET_152C is: {}%\".format(RESNET_152A_attack_top1_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "id": "UhfsLv0MqqNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb80e9b7-0e62-4680-edad-ca5064b99803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on RESNET_152A_attacked identity images for IR_152A is: 0.0%\n",
            "The top1 Accuracy on RESNET_152A_attacked identity images for IR_152C is: 0.0%\n",
            "The top1 Accuracy on RESNET_152A_attacked identity images for RESNET_152A is: 0.0%\n",
            "The top1 Accuracy on RESNET_152A_attacked identity images for RESNET_152C is: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top5 Accuracy on RESNET_152A_attacked identity images for IR_152A is: {}%\".format(RESNET_152A_attack_top5_accuracy_IR152A *100))\n",
        "print(\"The top5 Accuracy on RESNET_152A_attacked identity images for IR_152C is: {}%\".format(RESNET_152A_attack_top5_accuracy_IR152C *100))\n",
        "print(\"The top5 Accuracy on RESNET_152A_attacked identity images for RESNET_152A is: {}%\".format(RESNET_152A_attack_top5_accuracy_RESNET152A *100))\n",
        "print(\"The top5 Accuracy on RESNET_152A_attacked identity images for RESNET_152C is: {}%\".format(RESNET_152A_attack_top5_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "id": "RnRA-cb_q2ah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ba2cab-d12b-44ce-b387-96aab55dfda7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on RESNET_152A_attacked identity images for IR_152A is: 0.0%\n",
            "The top5 Accuracy on RESNET_152A_attacked identity images for IR_152C is: 0.0%\n",
            "The top5 Accuracy on RESNET_152A_attacked identity images for RESNET_152A is: 5.714285714285714%\n",
            "The top5 Accuracy on RESNET_152A_attacked identity images for RESNET_152C is: 2.857142857142857%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tableEvaluation4 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation4.title = 'Evaluation pipeline Top 1'\n",
        "tableEvaluation4.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation4.add_row(['clean_images_Feature_1', clean_top1_accuracy_IR152A*100,clean_top1_accuracy_IR152C*100,clean_top1_accuracy_RESNET152A*100,clean_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation4.add_row(['Ensemble_attack_Feature_1',adversial_top1_accuracy_IR152A*100,adversial_top1_accuracy_IR152C*100, adversial_top1_accuracy_RESNET152A*100,adversial_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation4.add_row(['Lowkey_ensemble_attack_5_directories',lowkey_top1_accuracy_IR152A *100,lowkey_top1_accuracy_IR152C *100, lowkey_top1_accuracy_RESNET152A *100,lowkey_top1_accuracy_RESNET152A *100])\n",
        "tableEvaluation4.add_row(['IR_152_ArcFace_attack_5_directories',IR_152A_attack_top1_accuracy_IR152A *100,IR_152A_attack_top1_accuracy_IR152C *100, IR_152A_attack_top1_accuracy_RESNET152A *100,IR_152A_attack_top1_accuracy_RESNET152C *100])\n",
        "tableEvaluation4.add_row(['IR_152_CosFace_attack_5_directories',IR_152C_attack_top1_accuracy_IR152A *100,IR_152C_attack_top1_accuracy_IR152C *100, IR_152C_attack_top1_accuracy_RESNET152A *100,IR_152C_attack_top1_accuracy_RESNET152C *100])\n",
        "tableEvaluation4.add_row(['RESNET_152_ArcFace_attack_5_directories',RESNET_152A_attack_top1_accuracy_IR152A *100,RESNET_152A_attack_top1_accuracy_IR152C *100, RESNET_152A_attack_top1_accuracy_RESNET152A *100,RESNET_152A_attack_top1_accuracy_RESNET152C *100])\n",
        "\n",
        "print(tableEvaluation4)\n"
      ],
      "metadata": {
        "id": "d2HkLGR2q9P7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c65cd3fe-a291-4f61-cb5f-befdf71e538c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                Evaluation pipeline Top 1                                                |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|                 Attacker                |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|          clean_images_Feature_1         | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |\n",
            "|        Ensemble_attack_Feature_1        | 78.80794701986756 | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 |\n",
            "|   Lowkey_ensemble_attack_5_directories  |        0.0        |        0.0        |        0.0        |        0.0        |\n",
            "|   IR_152_ArcFace_attack_5_directories   |        0.0        |        0.0        |        0.0        |        0.0        |\n",
            "|   IR_152_CosFace_attack_5_directories   |        0.0        |        0.0        | 2.857142857142857 |        0.0        |\n",
            "| RESNET_152_ArcFace_attack_5_directories |        0.0        |        0.0        |        0.0        |        0.0        |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tableEvaluation3 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation3.title = 'Evaluation pipeline Top 5'\n",
        "tableEvaluation3.field_names = ['Attacker','IR_152A', 'IR_152C','RESNET_152A','RESNET_152C']\n",
        "tableEvaluation3.add_row(['clean_images_Feature_1', clean_top1_accuracy_IR152A*100,clean_top1_accuracy_IR152C*100,clean_top1_accuracy_RESNET152A*100,clean_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation3.add_row(['Ensemble_attack_Feature_1',adversial_top1_accuracy_IR152A*100,adversial_top1_accuracy_IR152C*100, adversial_top1_accuracy_RESNET152A*100,adversial_top1_accuracy_RESNET152C*100])\n",
        "tableEvaluation3.add_row(['Lowkey_ensemble_attack_5_directories',lowkey_top5_accuracy_IR152A *100,lowkey_top5_accuracy_IR152C *100, lowkey_top5_accuracy_RESNET152A *100,lowkey_top5_accuracy_RESNET152A *100])\n",
        "tableEvaluation3.add_row(['IR_152_ArcFace_attack_5_directories',IR_152A_attack_top5_accuracy_IR152A *100,IR_152A_attack_top5_accuracy_IR152C *100, IR_152A_attack_top5_accuracy_RESNET152A *100,IR_152A_attack_top5_accuracy_RESNET152C *100])\n",
        "tableEvaluation3.add_row(['IR_152_CosFace_attack_5_directories',IR_152C_attack_top5_accuracy_IR152A *100,IR_152C_attack_top5_accuracy_IR152C *100, IR_152C_attack_top5_accuracy_RESNET152A *100,IR_152C_attack_top5_accuracy_RESNET152C *100])\n",
        "tableEvaluation3.add_row(['RESNET_152_ArcFace_attack_5_directories',RESNET_152A_attack_top5_accuracy_IR152A *100,RESNET_152A_attack_top5_accuracy_IR152C *100, RESNET_152A_attack_top5_accuracy_RESNET152A *100,RESNET_152A_attack_top5_accuracy_RESNET152C *100])\n",
        "\n",
        "print(tableEvaluation3)\n"
      ],
      "metadata": {
        "id": "VKlWjJ6DrT5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b29c1d-1174-454e-96d9-f609c2e1c586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                Evaluation pipeline Top 5                                                |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|                 Attacker                |      IR_152A      |      IR_152C      |    RESNET_152A    |    RESNET_152C    |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n",
            "|          clean_images_Feature_1         | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 | 99.33774834437085 |\n",
            "|        Ensemble_attack_Feature_1        | 78.80794701986756 | 79.47019867549669 | 79.47019867549669 | 79.47019867549669 |\n",
            "|   Lowkey_ensemble_attack_5_directories  |        0.0        | 2.857142857142857 | 8.571428571428571 | 8.571428571428571 |\n",
            "|   IR_152_ArcFace_attack_5_directories   |        0.0        |        0.0        |        0.0        | 2.857142857142857 |\n",
            "|   IR_152_CosFace_attack_5_directories   |        0.0        |        0.0        | 2.857142857142857 | 5.714285714285714 |\n",
            "| RESNET_152_ArcFace_attack_5_directories |        0.0        |        0.0        | 5.714285714285714 | 2.857142857142857 |\n",
            "+-----------------------------------------+-------------------+-------------------+-------------------+-------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Now finally Performing attack with RESNET_152C Model and calculating top 1 and top5 accuracy\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5tKVb1jCLKk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################Now lets do it finally for RESNET_152C\n",
        "# Now lets attack with RESNETCosFace_152 Model\n",
        "RESNET_152C_attack_id_1 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody\"\n",
        "RESNET_152C_attack_id_2 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina\"\n",
        "RESNET_152C_attack_id_3 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia\"\n",
        "RESNET_152C_attack_id_4 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis\"\n",
        "RESNET_152C_attack_id_5 = \"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck\"\n",
        "\n"
      ],
      "metadata": {
        "id": "g-ocuzD_r5na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152C_attack_id_1,model=model_RESNET_152C_list)"
      ],
      "metadata": {
        "id": "LFGBv7sQsG8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae45de0-4268-4c72-ceff-51c7636f8326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/69 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_592_371.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/69 [00:12<14:20, 12.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_659_409.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/69 [00:24<13:20, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_636_399.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/69 [00:35<12:57, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_616_384.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/69 [00:47<12:34, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_657_408.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/69 [00:58<12:19, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_650_405.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 6/69 [01:10<12:09, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_600_374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/69 [01:21<11:57, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_687_422.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/69 [01:33<11:43, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_620_387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/69 [01:44<11:29, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_635_398.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/69 [01:56<11:19, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_686_421.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/69 [02:08<11:25, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_619_386.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/69 [02:20<11:06, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_610_381.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/69 [02:31<10:53, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_700_427.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 14/69 [02:43<10:37, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_644_402.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/69 [02:54<10:21, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_722_432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/69 [03:05<10:08, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_651_406.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▍       | 17/69 [03:17<09:57, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_630_395.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 18/69 [03:30<10:06, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_681_418.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/69 [03:41<09:49, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_632_396.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/69 [03:53<09:34, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_567_363.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 21/69 [04:05<09:24, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_586_369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/69 [04:17<09:15, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_530_343.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 23/69 [04:28<09:00, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_683_419.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▍      | 24/69 [04:40<08:46, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_495_322.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 25/69 [04:51<08:31, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_480_311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/69 [05:02<08:16, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_522_339.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 27/69 [05:14<08:04, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_529_342.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/69 [05:25<07:52, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_471_308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 29/69 [05:37<07:38, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_491_320.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 30/69 [05:48<07:25, 11.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_469_307.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▍     | 31/69 [06:00<07:13, 11.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_518_336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 32/69 [06:12<07:15, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_570_365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 33/69 [06:24<06:59, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_603_377.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 34/69 [06:35<06:43, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_604_378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 35/69 [06:46<06:29, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_475_310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 36/69 [06:58<06:18, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_506_328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 37/69 [07:09<06:08, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_487_318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 38/69 [07:21<05:55, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_450_295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/69 [07:32<05:43, 11.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_542_349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 40/69 [07:43<05:31, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_601_375.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 41/69 [07:55<05:20, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_460_302.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 42/69 [08:07<05:15, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_508_330.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 43/69 [08:19<05:02, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_554_356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 44/69 [08:30<04:48, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_564_362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 45/69 [08:41<04:36, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_621_388.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 46/69 [08:53<04:24, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_486_317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 47/69 [09:04<04:12, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_445_293.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|██████▉   | 48/69 [09:16<04:01, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_360_238.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 49/69 [09:27<03:49, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_422_277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 50/69 [09:39<03:39, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_426_281.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 51/69 [09:52<03:34, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_355_235.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 52/69 [10:04<03:22, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_391_254.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 53/69 [10:16<03:11, 11.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_428_283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 54/69 [10:27<02:57, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_371_244.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 55/69 [10:39<02:46, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_435_287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 56/69 [10:51<02:33, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_427_282.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 57/69 [11:03<02:21, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_440_290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 58/69 [11:14<02:09, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_485_316.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 59/69 [11:26<01:56, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_374_246.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 60/69 [11:37<01:44, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_395_258.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 61/69 [11:49<01:32, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_411_269.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 62/69 [12:00<01:20, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_364_240.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████▏| 63/69 [12:13<01:11, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_379_249.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 64/69 [12:25<00:59, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_405_264.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 65/69 [12:36<00:47, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_409_267.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 66/69 [12:48<00:35, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_394_257.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 67/69 [13:00<00:23, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_375_247.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 68/69 [13:11<00:11, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Adam_Brody/Adam_Brody_398_260.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 69/69 [13:23<00:00, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152C_attack_id_2,model=model_RESNET_152C_list)"
      ],
      "metadata": {
        "id": "bdlbBCn_sOYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1b0101-780c-43f8-db25-8f5d71be55d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/42 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4201_2532.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/42 [00:11<07:56, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4271_2575.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 2/42 [00:23<07:45, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4203_2534.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 3/42 [00:34<07:33, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4224_2548.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 4/42 [00:47<07:38, 12.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4284_2580.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 5/42 [00:59<07:21, 11.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2453.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 6/42 [01:11<07:07, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4008_2416.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 7/42 [01:22<06:52, 11.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4052_2444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 8/42 [01:34<06:40, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4109_2483.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██▏       | 9/42 [01:46<06:29, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4028_2429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 10/42 [01:57<06:16, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3959_2378.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 11/42 [02:09<06:04, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4032_2433.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▊       | 12/42 [02:21<05:52, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4170_2514.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 13/42 [02:33<05:40, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4207_2536.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 14/42 [02:45<05:34, 11.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4062_2454.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 15/42 [02:57<05:18, 11.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3997_2407.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 16/42 [03:08<05:05, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4067_2457.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 17/42 [03:20<04:51, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4057_2449.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 18/42 [03:31<04:40, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4007_2415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 19/42 [03:43<04:26, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4053_2445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 20/42 [03:54<04:14, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4030_2431.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 21/42 [04:06<04:03, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4214_2543.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 22/42 [04:18<03:51, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4078_2467.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 23/42 [04:29<03:39, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4014_2420.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 24/42 [04:42<03:34, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4191_2525.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|█████▉    | 25/42 [04:53<03:20, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4125_2491.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 26/42 [05:05<03:06, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3994_2404.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 27/42 [05:16<02:54, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3942_2364.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 28/42 [05:28<02:42, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3947_2369.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 29/42 [05:39<02:30, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3939_2361.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████▏  | 30/42 [05:51<02:18, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4002_2412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 31/42 [06:03<02:07, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3975_2390.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 32/42 [06:14<01:55, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3940_2362.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▊  | 33/42 [06:25<01:43, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4096_2477.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 34/42 [06:38<01:34, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3952_2372.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 35/42 [06:50<01:22, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_4009_2417.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 36/42 [07:01<01:10, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3944_2366.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 37/42 [07:13<00:58, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3977_2392.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 38/42 [07:25<00:46, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3957_2376.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 39/42 [07:36<00:35, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3943_2365.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 40/42 [07:48<00:23, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3971_2387.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 41/42 [07:59<00:11, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Alfred_Molina/Alfred_Molina_3938_2360.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [08:11<00:00, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152C_attack_id_3,model=model_RESNET_152C_list)"
      ],
      "metadata": {
        "id": "bQjVAMHZsPKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa228a7-86db-4fcd-93df-12cb3f72b6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/68 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5294_3049.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/68 [00:11<12:40, 11.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5253_3022.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/68 [00:23<13:13, 12.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5246_3017.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/68 [00:35<12:42, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5193_2976.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/68 [00:46<12:23, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5228_3003.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/68 [00:58<12:10, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5226_3001.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/68 [01:09<11:52, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5271_3034.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 7/68 [01:20<11:37, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5270_3033.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 8/68 [01:32<11:23, 11.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5265_3029.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/68 [01:43<11:13, 11.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5237_3011.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▍        | 10/68 [01:55<11:01, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5249_3019.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 11/68 [02:06<10:49, 11.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5262_3028.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 12/68 [02:19<11:06, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5250_3020.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 13/68 [02:31<10:54, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5233_3008.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 14/68 [02:44<10:57, 12.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5281_3043.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 15/68 [02:55<10:36, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5128_2929.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▎       | 16/68 [03:07<10:19, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5133_2933.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 17/68 [03:19<10:05, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5091_2902.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▋       | 18/68 [03:31<09:53, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5190_2973.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 19/68 [03:42<09:41, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5058_2875.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 20/68 [03:54<09:29, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5101_2910.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 21/68 [04:06<09:16, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5054_2871.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 22/68 [04:19<09:15, 12.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5132_2932.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 23/68 [04:30<08:56, 11.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5199_2982.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 24/68 [04:42<08:41, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5201_2983.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 25/68 [04:53<08:23, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5167_2956.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 26/68 [05:05<08:11, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5227_3002.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|███▉      | 27/68 [05:17<08:00, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5094_2904.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 28/68 [05:29<07:49, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5148_2943.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 29/68 [05:40<07:36, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5162_2951.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 30/68 [05:52<07:24, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5118_2921.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 31/68 [06:04<07:12, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5149_2944.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 32/68 [06:17<07:23, 12.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5090_2901.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▊     | 33/68 [06:29<07:03, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5184_2968.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 34/68 [06:41<06:48, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5176_2961.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████▏    | 35/68 [06:53<06:35, 11.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5082_2894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 36/68 [07:05<06:23, 11.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5178_2962.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 37/68 [07:16<06:10, 11.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4981_2809.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 38/68 [07:28<05:56, 11.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4992_2820.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 39/68 [07:40<05:41, 11.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4995_2822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 40/68 [07:52<05:31, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5023_2845.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 41/68 [08:04<05:21, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5002_2829.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 42/68 [08:16<05:13, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5048_2867.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 43/68 [08:28<04:57, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4979_2807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 44/68 [08:39<04:41, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5053_2870.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 45/68 [08:51<04:29, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5006_2833.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 46/68 [09:02<04:16, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4999_2826.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 47/68 [09:14<04:05, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5045_2864.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 48/68 [09:26<03:54, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4967_2796.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 49/68 [09:38<03:43, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4983_2811.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▎  | 50/68 [09:50<03:32, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5052_2869.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 51/68 [10:02<03:24, 12.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4977_2805.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▋  | 52/68 [10:14<03:13, 12.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4972_2800.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 53/68 [10:26<03:00, 12.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5034_2853.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 54/68 [10:38<02:48, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5003_2830.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 55/68 [10:50<02:35, 12.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5040_2859.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 56/68 [11:02<02:23, 11.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5019_2843.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 57/68 [11:14<02:11, 11.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5037_2856.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 58/68 [11:26<01:59, 11.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4966_2795.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 59/68 [11:38<01:46, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4975_2803.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 60/68 [11:50<01:34, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5050_2868.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|████████▉ | 61/68 [12:02<01:24, 12.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4996_2823.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 62/68 [12:14<01:11, 11.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5055_2872.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 63/68 [12:26<00:59, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4961_2791.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 64/68 [12:37<00:47, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4959_2789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 65/68 [12:49<00:35, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_5046_2865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 66/68 [13:00<00:23, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4960_2790.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 67/68 [13:12<00:11, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Garcia/Andy_Garcia_4962_2792.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 68/68 [13:23<00:00, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152C_attack_id_4,model=model_RESNET_152C_list)"
      ],
      "metadata": {
        "id": "xJKDI2T3sPp2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d87595b-d56b-4331-d999-7353378f7fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5844_3393.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:11<09:24, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5875_3412.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:22<09:11, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5793_3359.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:35<09:23, 11.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5935_3444.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:47<09:02, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5904_3430.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:58<08:44, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5908_3432.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [01:10<08:30, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5903_3429.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [01:21<08:17, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5896_3424.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [01:32<08:04, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5880_3415.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [01:44<07:51, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5974_3459.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [01:55<07:41, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5871_3411.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [02:07<07:28, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5911_3435.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [02:18<07:17, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5914_3436.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [02:31<07:17, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5918_3439.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [02:42<07:01, 11.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5956_3451.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [02:54<06:46, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5726_3329.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [03:05<06:32, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5738_3335.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [03:17<06:22, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5772_3349.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [03:29<06:11, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5869_3410.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [03:40<06:00, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5725_3328.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [03:52<05:50, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5700_3317.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [04:03<05:35, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5792_3358.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [04:15<05:22, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5936_3445.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [04:27<05:20, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5688_3310.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [04:39<05:05, 11.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5657_3291.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [04:50<04:51, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5813_3374.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [05:02<04:37, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5664_3295.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [05:13<04:24, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5737_3334.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [05:24<04:11, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5701_3318.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [05:36<03:58, 11.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5782_3354.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [05:47<03:48, 11.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5762_3345.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [05:59<03:37, 11.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5697_3315.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [06:10<03:25, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5751_3340.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [06:22<03:19, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5740_3336.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [06:34<03:06, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5790_3356.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [06:45<02:53, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5707_3321.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [06:57<02:41, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5689_3311.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [07:08<02:29, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5720_3327.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [07:19<02:17, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5634_3273.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [07:31<02:06, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5677_3304.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [07:42<01:54, 11.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5640_3278.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [07:54<01:43, 11.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5666_3296.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [08:05<01:31, 11.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5641_3279.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [08:17<01:21, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5648_3283.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [08:29<01:09, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5639_3277.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [08:40<00:57, 11.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5635_3274.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [08:52<00:46, 11.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5651_3286.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [09:03<00:34, 11.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5652_3287.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [09:14<00:22, 11.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5656_3290.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [09:27<00:11, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Andy_Serkis/Andy_Serkis_5685_3308.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [09:38<00:00, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# protect_dir(dirs_root=RESNET_152C_attack_id_5,model=model_RESNET_152C_list)"
      ],
      "metadata": {
        "id": "_iCOHVnMsQEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e4d459-b824-4586-d910-6475447afd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/64 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8812_4907.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/64 [00:11<12:10, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8794_4894.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/64 [00:23<11:52, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8782_4885.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 3/64 [00:34<11:38, 11.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8809_4905.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 4/64 [00:46<11:51, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8749_4863.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 5/64 [00:58<11:31, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8670_4807.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 6/64 [01:09<11:16, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8697_4828.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 7/64 [01:21<11:00, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8814_4909.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 8/64 [01:32<10:46, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8802_4898.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 9/64 [01:44<10:35, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8619_4773.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 10/64 [01:55<10:23, 11.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8648_4793.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 11/64 [02:07<10:12, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8718_4842.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 12/64 [02:19<10:03, 11.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8781_4884.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 13/64 [02:31<10:07, 11.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8687_4821.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 14/64 [02:43<09:51, 11.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8746_4860.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 15/64 [02:54<09:34, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8708_4835.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 16/64 [03:06<09:20, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8571_4741.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 17/64 [03:18<09:06, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8734_4854.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 18/64 [03:29<08:52, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8551_4729.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 19/64 [03:41<08:41, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8564_4738.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███▏      | 20/64 [03:52<08:28, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8576_4744.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 21/64 [04:04<08:17, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8680_4814.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 22/64 [04:15<08:05, 11.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8568_4740.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 23/64 [04:28<08:05, 11.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8751_4865.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 24/64 [04:39<07:49, 11.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8760_4873.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 25/64 [04:51<07:36, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8588_4752.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 26/64 [05:02<07:24, 11.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8689_4822.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 27/64 [05:14<07:10, 11.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8810_4906.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 28/64 [05:25<06:57, 11.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8641_4789.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 29/64 [05:37<06:48, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8703_4831.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 30/64 [05:49<06:36, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8824_4916.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 31/64 [06:01<06:24, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8557_4733.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 32/64 [06:12<06:13, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8522_4703.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 33/64 [06:25<06:10, 11.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8496_4684.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 34/64 [06:36<05:53, 11.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8479_4675.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 35/64 [06:49<05:49, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8511_4694.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 36/64 [07:00<05:32, 11.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8480_4676.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 37/64 [07:12<05:17, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8586_4750.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 38/64 [07:23<05:03, 11.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8525_4705.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 39/64 [07:35<04:48, 11.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8508_4691.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 40/64 [07:46<04:36, 11.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8537_4716.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 41/64 [07:58<04:24, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8518_4699.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 42/64 [08:09<04:12, 11.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8681_4815.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 43/64 [08:22<04:08, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8617_4771.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 44/64 [08:33<03:54, 11.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8477_4673.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 45/64 [08:45<03:42, 11.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8779_4882.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 46/64 [08:56<03:29, 11.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8563_4737.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 47/64 [09:08<03:15, 11.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8456_4657.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 48/64 [09:19<03:03, 11.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8549_4727.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 49/64 [09:30<02:52, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8462_4663.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 50/64 [09:42<02:40, 11.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8519_4700.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|███████▉  | 51/64 [09:54<02:30, 11.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8470_4669.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████▏ | 52/64 [10:06<02:20, 11.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8603_4762.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 53/64 [10:18<02:10, 11.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8572_4742.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 54/64 [10:29<01:57, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8539_4718.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 55/64 [10:41<01:44, 11.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8486_4681.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 56/64 [10:52<01:32, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8607_4765.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 57/64 [11:05<01:23, 11.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8556_4732.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 58/64 [11:16<01:10, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8526_4706.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 59/64 [11:28<00:58, 11.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8566_4739.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 60/64 [11:39<00:46, 11.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 61/64 [11:51<00:34, 11.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8461_4662.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 62/64 [12:03<00:23, 11.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8471_4670.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 63/64 [12:15<00:11, 11.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n",
            "The image processed is : /content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8476_4672.jpeg\n",
            "Finding reference points\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.8/dist-packages/lpips/weights/v0.1/alex.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [12:27<00:00, 11.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "attack Executed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets define a loader for IR_152_attacked gallery\n",
        "RESNET_152C_attack_gallery_root = '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery' #90% of validation data\n",
        "# Generate Dataset\n",
        "RESNET_152C_attack_gallery_dataset = datasets.ImageFolder(RESNET_152C_attack_gallery_root, transform)\n",
        "\n",
        "# Generate loader with batch size = 16\n",
        "RESNET_152C_attack_gallery_loader = torch.utils.data.DataLoader(RESNET_152C_attack_gallery_dataset, batch_size = 16, shuffle = False, pin_memory = True, num_workers = 0)\n"
      ],
      "metadata": {
        "id": "M16xRXWUsV0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets generate the features for IR_152C_attacked identities\n",
        "from matplotlib.patches import Arc\n",
        "#Lets extract features for IR_152A\n",
        "attack_RESNET152C_labels_IR_152A,attack_RESNET152C_images_IR_152A,attack_RESNET152C_features_IR_152A = extract_feature_face(loader=RESNET_152C_attack_gallery_loader,model=IR_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_IR_152A.npy\", attack_RESNET152C_labels_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__images_IR_152A.npy\", attack_RESNET152C_images_IR_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_IR_152A.npy\", attack_RESNET152C_features_IR_152A)\n",
        "\n",
        "#Lets extract features for IR_152C\n",
        "attack_RESNET152C_labels_IR_152C,attack_RESNET152C_images_IR_152C,attack_RESNET152C_features_IR_152C = extract_feature_face(loader=RESNET_152C_attack_gallery_loader,model=IR_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_IR_152C.npy\", attack_RESNET152C_labels_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__images_IR_152C.npy\", attack_RESNET152C_images_IR_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_IR_152C.npy\", attack_RESNET152C_features_IR_152C)\n",
        "\n",
        "#Lets extract features for RESNET_152A\n",
        "attack_RESNET152C_labels_RESNET_152A,attack_RESNET152C_images_RESNET_152A,attack_RESNET152C_features_RESNET_152A = extract_feature_face(loader=RESNET_152C_attack_gallery_loader,model=RESNET_152A,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_RESNET_152A.npy\", attack_RESNET152C_labels_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__images_RESNET_152A.npy\", attack_RESNET152C_images_RESNET_152A)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_RESNET_152A.npy\", attack_RESNET152C_features_RESNET_152A)\n",
        "\n",
        "#extract gallery features for RESNET_152C\n",
        "\n",
        "attack_RESNET152C_labels_RESNET_152C,attack_RESNET152C_images_RESNET_152C,attack_RESNET152C_features_RESNET_152C = extract_feature_face(loader=RESNET_152C_attack_gallery_loader,model=RESNET_152C,embedding_size=EMBEDDING_SIZE,device=device)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_RESNET_152C.npy\", attack_RESNET152C_labels_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__images_RESNET_152C.npy\", attack_RESNET152C_images_RESNET_152C)\n",
        "np.save(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_RESNET_152C.npy\", attack_RESNET152C_features_RESNET_152C)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VeELixU6sr5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c580fdff-80e5-4983-f31a-f22dd675158f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes: 24\n",
            "============================================================\n",
            "Features zeros shape: (1264, 512)\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 16\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 32\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 48\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 64\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 80\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 96\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 112\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 128\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 144\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 160\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 176\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 192\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 208\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 224\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 240\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 256\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 272\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 288\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 304\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 320\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 336\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 352\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 368\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 384\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 400\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 416\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 432\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 448\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 464\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 480\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 496\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 512\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 528\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 544\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 560\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 576\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 592\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 608\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 624\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 640\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n",
            "============================================================\n",
            "Features l2_norm shape else : (1264, 512)\n",
            "The value of idx is : 656\n",
            "============================================================\n",
            "idx + batch_size <= len(loader.dataset)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-7bd6f96f2e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Lets extract features for IR_152A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mattack_RESNET152C_labels_IR_152A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattack_RESNET152C_images_IR_152A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattack_RESNET152C_features_IR_152A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feature_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRESNET_152C_attack_gallery_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIR_152A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_IR_152A.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_RESNET152C_labels_IR_152A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__images_IR_152A.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_RESNET152C_images_IR_152A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f898b73e27e2>\u001b[0m in \u001b[0;36mextract_feature_face\u001b[0;34m(loader, model, embedding_size, batch_size, device, tta)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"idx + batch_size <= len(loader.dataset)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml2_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[1;32m    228\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create the loader for these directories\n",
        "attack_RESNET152C_labels_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_IR_152A.npy\")\n",
        "attack_RESNET152C_features_IR_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_IR_152A.npy\")\n",
        "\n",
        "attack_RESNET152C_labels_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_IR_152C.npy\")\n",
        "attack_RESNET152C_features_IR_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_IR_152C.npy\")\n",
        "\n",
        "\n",
        "attack_RESNET152C_labels_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_RESNET_152A.npy\")\n",
        "attack_RESNET152C_features_RESNET_152A = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_RESNET_152A.npy\")\n",
        "\n",
        "attack_RESNET152C_labels_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__labels_RESNET_152C.npy\")\n",
        "attack_RESNET152C_features_RESNET_152C = np.load(\"/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery_features/attack_RESNET152C__features_RESNET_152C.npy\")\n"
      ],
      "metadata": {
        "id": "UYcdUFUHtpBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "RESNET_152C_attack_top1_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_RESNET152C_features_IR_152A,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_IR_152A,k=1)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "RESNET_152C_attack_top1_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_RESNET152C_features_IR_152C,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_IR_152C,k=1)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "RESNET_152C_attack_top1_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_RESNET152C_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_RESNET_152A,k=1)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "RESNET_152C_attack_top1_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_RESNET152C_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_RESNET_152C,k=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "wBt6exX0wjsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8147b5-9449-46e7-9433-c74957a7f682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 93.46it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 91.68it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 89.74it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 93.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets calculate top1 accuracy\n",
        "# now lets calculate the lowkey accuracies\n",
        "# calculate accuracy for IR_152A\n",
        "RESNET_152C_attack_top5_accuracy_IR152A = get_accuracy(probe_features=all_attack_probe_features_IR_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152A,\n",
        "                                          gallery_features=attack_RESNET152C_features_IR_152A,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_IR_152A,k=3)\n",
        "\n",
        "# calculate accuracy for IR_152C\n",
        "RESNET_152C_attack_top5_accuracy_IR152C = get_accuracy(probe_features=all_attack_probe_features_IR_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_IR_152C,\n",
        "                                          gallery_features=attack_RESNET152C_features_IR_152C,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_IR_152C,k=3)\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "RESNET_152C_attack_top5_accuracy_RESNET152A = get_accuracy(probe_features=all_attack_probe_features_RESNET_152A,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152A,\n",
        "                                          gallery_features=attack_RESNET152C_features_RESNET_152A,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_RESNET_152A,k=3)\n",
        "\n",
        "\n",
        "# calculate accuracy for RESNET_152C\n",
        "\n",
        "RESNET_152C_attack_top5_accuracy_RESNET152C = get_accuracy(probe_features=all_attack_probe_features_RESNET_152C,\n",
        "                                               probe_labels=all_attack_probe_labels_RESNET_152C,\n",
        "                                          gallery_features=attack_RESNET152C_features_RESNET_152C,\n",
        "                                          gallery_labels=attack_RESNET152C_labels_RESNET_152C,k=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "JZPNPyVnw60N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385dee01-e7bc-4807-9919-300ce8998dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 69.88it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 50.93it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 95.78it/s]\n",
            "100%|██████████| 35/35 [00:00<00:00, 96.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top1 Accuracy on RESNET_152C_attacked identity images for IR_152A is: {}%\".format(RESNET_152C_attack_top1_accuracy_IR152A *100))\n",
        "print(\"The top1 Accuracy on RESNET_152C_attacked identity images for IR_152C is: {}%\".format(RESNET_152C_attack_top1_accuracy_IR152C *100))\n",
        "print(\"The top1 Accuracy on RESNET_152C_attacked identity images for RESNET_152A is: {}%\".format(RESNET_152C_attack_top1_accuracy_RESNET152A *100))\n",
        "print(\"The top1 Accuracy on RESNET_152C_attacked identity images for RESNET_152C is: {}%\".format(RESNET_152C_attack_top1_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "id": "30CZyP3HxFpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ef215c-802a-4cb5-9848-be7411e4b098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top1 Accuracy on RESNET_152C_attacked identity images for IR_152A is: 0.0%\n",
            "The top1 Accuracy on RESNET_152C_attacked identity images for IR_152C is: 0.0%\n",
            "The top1 Accuracy on RESNET_152C_attacked identity images for RESNET_152A is: 2.857142857142857%\n",
            "The top1 Accuracy on RESNET_152C_attacked identity images for RESNET_152C is: 2.857142857142857%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The top5 Accuracy on RESNET_152C_attacked identity images for IR_152A is: {}%\".format(RESNET_152C_attack_top5_accuracy_IR152A *100))\n",
        "print(\"The top5 Accuracy on RESNET_152C_attacked identity images for IR_152C is: {}%\".format(RESNET_152C_attack_top5_accuracy_IR152C *100))\n",
        "print(\"The top5 Accuracy on RESNET_152C_attacked identity images for RESNET_152A is: {}%\".format(RESNET_152C_attack_top5_accuracy_RESNET152A *100))\n",
        "print(\"The top5 Accuracy on RESNET_152C_attacked identity images for RESNET_152C is: {}%\".format(RESNET_152C_attack_top5_accuracy_RESNET152C *100))\n"
      ],
      "metadata": {
        "id": "NGrO5sVSxK5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe0cc60-68b5-430f-df56-3958ac47f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top5 Accuracy on RESNET_152C_attacked identity images for IR_152A is: 0.0%\n",
            "The top5 Accuracy on RESNET_152C_attacked identity images for IR_152C is: 0.0%\n",
            "The top5 Accuracy on RESNET_152C_attacked identity images for RESNET_152A is: 2.857142857142857%\n",
            "The top5 Accuracy on RESNET_152C_attacked identity images for RESNET_152C is: 5.714285714285714%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Now lets finally print all evaluation results in the table\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LzaCLRPWw1Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tableEvaluation5 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation5.title = 'Evaluation pipeline Top 1 - 5 identities'\n",
        "tableEvaluation5.field_names = ['Attacker','IR_152A', 'IR_152C','RN_152A','RN_152C']\n",
        "tableEvaluation5.add_row(['clean_images_all_gallery', round(clean_top1_accuracy_IR152A*100,2),round(clean_top1_accuracy_IR152C*100,2),round(clean_top1_accuracy_RESNET152A*100,2),round(clean_top1_accuracy_RESNET152C*100,2)])\n",
        "tableEvaluation5.add_row(['Ensemble_attack_all_gallery',round(adversial_top1_accuracy_IR152A*100,2),round(adversial_top1_accuracy_IR152C*100,2),round(adversial_top1_accuracy_RESNET152A*100,2),round(adversial_top1_accuracy_RESNET152C*100,2)])\n",
        "tableEvaluation5.add_row(['Ensemble_lowkey',round(lowkey_top1_accuracy_IR152A *100,2),round(lowkey_top1_accuracy_IR152C *100,2), round(lowkey_top1_accuracy_RESNET152A *100,2),round(lowkey_top1_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation5.add_row(['IR_152A',round(IR_152A_attack_top1_accuracy_IR152A *100,2),round(IR_152A_attack_top1_accuracy_IR152C *100,2), round(IR_152A_attack_top1_accuracy_RESNET152A *100,2),round(IR_152A_attack_top1_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation5.add_row(['IR_152C',round(IR_152C_attack_top1_accuracy_IR152A *100,2),round(IR_152C_attack_top1_accuracy_IR152C *100,2), round(IR_152C_attack_top1_accuracy_RESNET152A *100,2),round(IR_152C_attack_top1_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation5.add_row(['RN_152A',round(RESNET_152A_attack_top1_accuracy_IR152A *100,2),round(RESNET_152A_attack_top1_accuracy_IR152C *100,2), round(RESNET_152A_attack_top1_accuracy_RESNET152A *100,2),round(RESNET_152A_attack_top1_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation5.add_row(['RN_152C',round(RESNET_152C_attack_top1_accuracy_IR152A *100,2),round(RESNET_152C_attack_top1_accuracy_IR152C *100,2), round(RESNET_152C_attack_top1_accuracy_RESNET152A *100,2),round(RESNET_152C_attack_top1_accuracy_RESNET152C *100,2)])\n",
        "\n",
        "print(tableEvaluation5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8_GIUbmZ87i",
        "outputId": "5f678552-a395-4830-a0bb-9c865286fdce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+\n",
            "|               Evaluation pipeline Top 1 - 5 identities              |\n",
            "+-----------------------------+---------+---------+---------+---------+\n",
            "|           Attacker          | IR_152A | IR_152C | RN_152A | RN_152C |\n",
            "+-----------------------------+---------+---------+---------+---------+\n",
            "|   clean_images_all_gallery  |  99.34  |  99.34  |  99.34  |  99.34  |\n",
            "| Ensemble_attack_all_gallery |  78.81  |  79.47  |  79.47  |  79.47  |\n",
            "|       Ensemble_lowkey       |   0.0   |   0.0   |   0.0   |   0.0   |\n",
            "|           IR_152A           |   0.0   |   0.0   |   0.0   |   0.0   |\n",
            "|           IR_152C           |   0.0   |   0.0   |   2.86  |   0.0   |\n",
            "|           RN_152A           |   0.0   |   0.0   |   0.0   |   0.0   |\n",
            "|           RN_152C           |   0.0   |   0.0   |   2.86  |   2.86  |\n",
            "+-----------------------------+---------+---------+---------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tableEvaluation6 = PrettyTable()\n",
        "\n",
        "# Add data for table display\n",
        "\n",
        "tableEvaluation6.title = 'Evaluation pipeline Top 3 - 5 identities'\n",
        "tableEvaluation6.field_names = ['Attacker','IR_152A', 'IR_152C','RN_152A','RN_152C']\n",
        "tableEvaluation6.add_row(['clean_images_all_gallery', round(clean_top5_accuracy_IR152A*100,2),round(clean_top5_accuracy_IR152C*100,2),round(clean_top5_accuracy_RESNET152A*100,2),round(clean_top5_accuracy_RESNET152C*100,2)])\n",
        "tableEvaluation6.add_row(['Ensemble_attack_all_gallery',round(adversial_top5_accuracy_IR152A*100,2),round(adversial_top5_accuracy_IR152C*100,2),round(adversial_top5_accuracy_RESNET152A*100,2),round(adversial_top5_accuracy_RESNET152C*100,2)])\n",
        "tableEvaluation6.add_row(['Ensemble_lowkey',round(lowkey_top5_accuracy_IR152A *100,2),round(lowkey_top5_accuracy_IR152C *100,2), round(lowkey_top5_accuracy_RESNET152A *100,2),round(lowkey_top5_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation6.add_row(['IR_152A',round(IR_152A_attack_top5_accuracy_IR152A *100,2),round(IR_152A_attack_top5_accuracy_IR152C *100,2), round(IR_152A_attack_top5_accuracy_RESNET152A *100,2),round(IR_152A_attack_top5_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation6.add_row(['IR_152C',round(IR_152C_attack_top5_accuracy_IR152A *100,2),round(IR_152C_attack_top5_accuracy_IR152C *100,2), round(IR_152C_attack_top5_accuracy_RESNET152A *100,2),round(IR_152C_attack_top5_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation6.add_row(['RN_152A',round(RESNET_152A_attack_top5_accuracy_IR152A *100,2),round(RESNET_152A_attack_top5_accuracy_IR152C *100,2), round(RESNET_152A_attack_top5_accuracy_RESNET152A *100,2),round(RESNET_152A_attack_top5_accuracy_RESNET152C *100,2)])\n",
        "tableEvaluation6.add_row(['RN_152C',round(RESNET_152C_attack_top5_accuracy_IR152A *100,2),round(RESNET_152C_attack_top5_accuracy_IR152C *100,2), round(RESNET_152C_attack_top5_accuracy_RESNET152A *100,2),round(RESNET_152C_attack_top5_accuracy_RESNET152C *100,2)])\n",
        "\n",
        "print(tableEvaluation6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqr14zqYcmzO",
        "outputId": "19b0fe9a-b486-440b-ac29-447d89ddf090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+\n",
            "|               Evaluation pipeline Top 3 - 5 identities              |\n",
            "+-----------------------------+---------+---------+---------+---------+\n",
            "|           Attacker          | IR_152A | IR_152C | RN_152A | RN_152C |\n",
            "+-----------------------------+---------+---------+---------+---------+\n",
            "|   clean_images_all_gallery  |  99.34  |  99.34  |  99.34  |  100.0  |\n",
            "| Ensemble_attack_all_gallery |  79.47  |  79.47  |  79.47  |  80.13  |\n",
            "|       Ensemble_lowkey       |   0.0   |   2.86  |   8.57  |   5.71  |\n",
            "|           IR_152A           |   0.0   |   0.0   |   0.0   |   2.86  |\n",
            "|           IR_152C           |   0.0   |   0.0   |   2.86  |   5.71  |\n",
            "|           RN_152A           |   0.0   |   0.0   |   5.71  |   2.86  |\n",
            "|           RN_152C           |   0.0   |   0.0   |   2.86  |   5.71  |\n",
            "+-----------------------------+---------+---------+---------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "Clean_img = Image.open('/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/gallery/Ben_Affleck/Ben_Affleck_8455_4656.jpeg')\n",
        "ensemble_attack_img =Image.open('/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/Ensemble_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.protected.png')\n",
        "IR_152A_attack_img = Image.open( '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.protected.png')\n",
        "IR_152C_attack_img = Image.open('/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/IR_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.protected.png')\n",
        "RESNET_152A_attack_img = Image.open('/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152A_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.protected.png')\n",
        "RESNET_152C_attack_img =Image.open( '/content/drive/MyDrive/Lowkey code/faceScrub/actors/cleanData/dataAlign/adversial_data/RESNET_152C_attack/gallery/Ben_Affleck/Ben_Affleck_8455_4656.protected.png')"
      ],
      "metadata": {
        "id": "XOHhYIwlsLxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "idi1n4IFtiZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Clean_img_py= torchvision.transforms.Resize((300,300))(Clean_img)\n",
        "ensemble_attack_img_py= torchvision.transforms.Resize((300,300))(ensemble_attack_img)\n",
        "IR_152A_attack_img_py= torchvision.transforms.Resize((300,300))(IR_152A_attack_img)\n",
        "IR_152C_attack_img_py= torchvision.transforms.Resize((300,300))(IR_152C_attack_img)\n",
        "RESNET_152A_attack_img_py= torchvision.transforms.Resize((300,300))(RESNET_152A_attack_img)\n",
        "RESNET_152C_attack_img_py= torchvision.transforms.Resize((300,300))(RESNET_152C_attack_img)\n"
      ],
      "metadata": {
        "id": "MYobLLbptKyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting values to rows and column variables\n",
        "%matplotlib inline\n",
        "rows = 2\n",
        "columns = 3\n",
        "pic = 27\n",
        "\n",
        "# create figure\n",
        "fig = plt.figure(figsize=(13, 10))\n",
        "# Adds a subplot at the 1st position\n",
        "fig.add_subplot(rows, columns, 1)\n",
        "inputs1 = Clean_img_py\n",
        "# showing image\n",
        "plt.imshow(inputs1)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original\")\n",
        "\n",
        "\n",
        "# Adds a subplot at the 2st position\n",
        "fig.add_subplot(rows, columns, 2)\n",
        "inputs2 =ensemble_attack_img_py\n",
        "\n",
        "# showing image\n",
        "plt.imshow(inputs2)\n",
        "plt.axis('off')\n",
        "plt.title(\"Lowkey Ensemble attack\")\n",
        "\n",
        "# Adds a subplot at the 3rd position\n",
        "fig.add_subplot(rows, columns, 3)\n",
        "inputs3 =IR_152A_attack_img_py\n",
        "\n",
        "# showing image\n",
        "plt.imshow(inputs3)\n",
        "plt.axis('off')\n",
        "plt.title(\"IR 152 ArcFace attack\")\n",
        "\n",
        "\n",
        "# Adds a subplot at the 4th position\n",
        "fig.add_subplot(rows, columns, 4)\n",
        "inputs4 =IR_152C_attack_img_py\n",
        "\n",
        "# showing image\n",
        "plt.imshow(inputs4)\n",
        "plt.axis('off')\n",
        "plt.title(\"IR 152 CosFace attack\")\n",
        "\n",
        "# Adds a subplot at the 5th position\n",
        "fig.add_subplot(rows, columns, 5)\n",
        "inputs5 =RESNET_152A_attack_img_py\n",
        "\n",
        "# showing image\n",
        "plt.imshow(inputs5)\n",
        "plt.axis('off')\n",
        "plt.title(\"RESNET 152 ArcFace attack\")\n",
        "\n",
        "# Adds a subplot at the 5th position\n",
        "fig.add_subplot(rows, columns, 6)\n",
        "inputs6 =RESNET_152C_attack_img_py\n",
        "\n",
        "# showing image\n",
        "plt.imshow(inputs6)\n",
        "plt.axis('off')\n",
        "plt.title(\"RESNET 152 CosFace attack\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9fNm4K8hupI-",
        "outputId": "d1a49d10-398d-4671-bb70-1cc55caf2991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'RESNET 152 CosFace attack')"
            ]
          },
          "metadata": {},
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 936x720 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "031acb9ee2af4878a1508ee1cd1ff946": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1717def1ecbb45c3b23553916e5136b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "355a0e3ef6624af0b58e0c8ca42fd414": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abcacddd65654d4fad7f9900691955d8",
            "placeholder": "​",
            "style": "IPY_MODEL_3eed707e84dc43199719e5ac5a1b3f74",
            "value": "100%"
          }
        },
        "3eed707e84dc43199719e5ac5a1b3f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cb15a84bdba4d0fb417c9f8772ccfa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fd88c0b2e843c4a17c9e96acc2eddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b502139e69534d11a7e28a782ed32015",
            "placeholder": "​",
            "style": "IPY_MODEL_1717def1ecbb45c3b23553916e5136b4",
            "value": " 233M/233M [00:01&lt;00:00, 244MB/s]"
          }
        },
        "739cc4ed8e2a4147af64d845da8b191d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "836333dc9d2e435a8903e572565caeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "887e7d07863643f0a8c2690752cdc3df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b649c80e2742466bbbc7e69a5321611e",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_836333dc9d2e435a8903e572565caeee",
            "value": 244408911
          }
        },
        "891af9ef28404005810b6374e80ea819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dd501db6934417ebf626bec247a569b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92682188a8c143698fe99486dc52bd00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa18884468404ab2930318ab12f60f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9f5b75d95441efbc1c4ef919e05feb",
            "placeholder": "​",
            "style": "IPY_MODEL_891af9ef28404005810b6374e80ea819",
            "value": " 233M/233M [00:04&lt;00:00, 76.1MB/s]"
          }
        },
        "abcacddd65654d4fad7f9900691955d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abded15c77b64851b2433c29a9c85ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b865646675444ff5bd920db1101524ed",
              "IPY_MODEL_c45a4d624c6944b083a1d99a9812a953",
              "IPY_MODEL_aa18884468404ab2930318ab12f60f89"
            ],
            "layout": "IPY_MODEL_031acb9ee2af4878a1508ee1cd1ff946"
          }
        },
        "af9897863f4f4cc297f703150628a2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_355a0e3ef6624af0b58e0c8ca42fd414",
              "IPY_MODEL_887e7d07863643f0a8c2690752cdc3df",
              "IPY_MODEL_70fd88c0b2e843c4a17c9e96acc2eddf"
            ],
            "layout": "IPY_MODEL_8dd501db6934417ebf626bec247a569b"
          }
        },
        "b502139e69534d11a7e28a782ed32015": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b649c80e2742466bbbc7e69a5321611e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b865646675444ff5bd920db1101524ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfe08893fafe47a68f9ef1232e393a06",
            "placeholder": "​",
            "style": "IPY_MODEL_92682188a8c143698fe99486dc52bd00",
            "value": "100%"
          }
        },
        "c45a4d624c6944b083a1d99a9812a953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb15a84bdba4d0fb417c9f8772ccfa6",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_739cc4ed8e2a4147af64d845da8b191d",
            "value": 244408911
          }
        },
        "dfe08893fafe47a68f9ef1232e393a06": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9f5b75d95441efbc1c4ef919e05feb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67cd109a27de42939e73961f94ae6b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de88dac9aea74354abfa8f9250b51998",
              "IPY_MODEL_12ffe4823b1a4618b10641856daed088",
              "IPY_MODEL_985cb0aebd9b49f49b410c1179463a2e"
            ],
            "layout": "IPY_MODEL_92ee5771e1e547ff965caf7f11bc7fde"
          }
        },
        "de88dac9aea74354abfa8f9250b51998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ec514336cc417cb0269075763b6ae9",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe13ed52e7b484f850760c26a56d2c7",
            "value": "100%"
          }
        },
        "12ffe4823b1a4618b10641856daed088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752709f260234bf987b232cc4fdb44b0",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b22bab584a28488cb9ec5d19c9a77917",
            "value": 244408911
          }
        },
        "985cb0aebd9b49f49b410c1179463a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65eb8fa5a06406eb5604b81eab78724",
            "placeholder": "​",
            "style": "IPY_MODEL_090a5a4276e14a88a7f627781f831d6a",
            "value": " 233M/233M [00:02&lt;00:00, 87.0MB/s]"
          }
        },
        "92ee5771e1e547ff965caf7f11bc7fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ec514336cc417cb0269075763b6ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe13ed52e7b484f850760c26a56d2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "752709f260234bf987b232cc4fdb44b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b22bab584a28488cb9ec5d19c9a77917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f65eb8fa5a06406eb5604b81eab78724": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090a5a4276e14a88a7f627781f831d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da9a66ca2604463ab35d7cf1d6294b28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1f1eb7d962c4fc4b6c287cbe13d693e",
              "IPY_MODEL_b0779cd417bd47c193543fb7c7724309",
              "IPY_MODEL_ae06228bab744c45827fd2ad27c357a6"
            ],
            "layout": "IPY_MODEL_cb017a23d53d46319fcd4a942df36126"
          }
        },
        "f1f1eb7d962c4fc4b6c287cbe13d693e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616971fe0bf44d52a68f6d387a7cf970",
            "placeholder": "​",
            "style": "IPY_MODEL_f57bd1ae17414da388f9394fc13d5df5",
            "value": "100%"
          }
        },
        "b0779cd417bd47c193543fb7c7724309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c3521d1ba841848a3b7c7782d00577",
            "max": 244408911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d1a9c7231e346c29c7bd6f035503139",
            "value": 244408911
          }
        },
        "ae06228bab744c45827fd2ad27c357a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a54e8670d984dc6afecfccfc30c498a",
            "placeholder": "​",
            "style": "IPY_MODEL_697df47e39d54332881d0eb2941bc45c",
            "value": " 233M/233M [00:03&lt;00:00, 86.6MB/s]"
          }
        },
        "cb017a23d53d46319fcd4a942df36126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616971fe0bf44d52a68f6d387a7cf970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f57bd1ae17414da388f9394fc13d5df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3c3521d1ba841848a3b7c7782d00577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1a9c7231e346c29c7bd6f035503139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a54e8670d984dc6afecfccfc30c498a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "697df47e39d54332881d0eb2941bc45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}